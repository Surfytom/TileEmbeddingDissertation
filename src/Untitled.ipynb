{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assumed-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "from keras import metrics\n",
    "from utils.evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from utils.data_loading.load_data import get_tile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brazilian-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder_architecture import get_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indie-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model, ae_sep_output=get_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exciting-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv1 (Conv2D)          (None, 16, 16, 32)   896         image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 32)   128         iencode_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 16, 16, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv2 (Conv2D)          (None, 16, 16, 32)   9248        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 32)   128         iencode_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 16, 16, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv3 (Conv2D)          (None, 16, 16, 16)   4624        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16)   64          iencode_conv3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 16, 16, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tencode_dense1 (Dense)          (None, 32)           448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_flatten_layer (Flatten)   (None, 4096)         0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tencode_dense2 (Dense)          (None, 16)           528         tencode_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "image_text_concatenation (Conca (None, 4112)         0           image_flatten_layer[0][0]        \n",
      "                                                                 tencode_dense2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_dense_1 (Dense)       (None, 256)          1052928     image_text_concatenation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "image_dense (Dense)             (None, 4096)         1052672     embedding_dense_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "image_reshape (Reshape)         (None, 16, 16, 16)   0           image_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv1 (Conv2DTranspose) (None, 16, 16, 16)   2320        image_reshape[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm1 (BatchNormalizati (None, 16, 16, 16)   64          idecode_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu1 (ReLU)            (None, 16, 16, 16)   0           idecode_norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv2 (Conv2DTranspose) (None, 16, 16, 32)   4640        idecode_relu1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense1 (Dense)          (None, 16)           4112        embedding_dense_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm2 (BatchNormalizati (None, 16, 16, 32)   128         idecode_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_reshape (Reshape)          (None, 16)           0           tdecode_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu2 (ReLU)            (None, 16, 16, 32)   0           idecode_norm2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense2 (Dense)          (None, 32)           544         text_reshape[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "image_output_layer (Conv2DTrans (None, 16, 16, 3)    867         idecode_relu2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_output_layer (Dense)       (None, 13)           429         tdecode_dense2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,134,768\n",
      "Trainable params: 2,134,512\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_sep_output.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-cream",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_embeddings",
   "language": "python",
   "name": "tile_embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
