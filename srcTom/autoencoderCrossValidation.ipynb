{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils.PTModel.Losses as Losses\n",
    "import Utils.PTModel.Models as Models\n",
    "import Utils.Data.DataLoading as DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wall', 'element', 'pipe', 'passable', 'block', 'solid', 'moving', 'openable', 'hazard', 'climbable', 'collectable', 'empty', 'breakable'}\n",
      "tensor([3.6799, 3.9129, 5.4777, 1.9535, 3.4377, 1.5683, 5.0192, 4.7846, 4.4612,\n",
      "        4.9633, 5.0192, 2.0802, 4.4744])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surfytom/Projects/Dissertation/Repos/TileEmbeddingDissertation/srcTom/Utils/Data/DataLoading.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 6.8108, 1.5074, 0.0000, 1.9175, 6.3522, 7.5223, 4.8912,\n",
      "        2.5969, 3.9553, 2.0638, 2.4590])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surfytom/Projects/Dissertation/Repos/TileEmbeddingDissertation/srcTom/Utils/Data/DataLoading.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0217, 5.2547, 6.8195, 1.5749, 4.7795, 1.8468, 6.6372, 6.1263, 5.0308,\n",
      "        2.6287, 4.0014, 2.1699, 2.4773])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surfytom/Projects/Dissertation/Repos/TileEmbeddingDissertation/srcTom/Utils/Data/DataLoading.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0529, 5.2859, 6.8507, 1.5881, 4.8106, 1.8553, 6.8327, 6.4272, 4.9445,\n",
      "        2.6360, 3.9953, 2.1532, 2.4989])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surfytom/Projects/Dissertation/Repos/TileEmbeddingDissertation/srcTom/Utils/Data/DataLoading.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0540, 5.2870, 0.0000, 1.5883, 4.8118, 1.8340, 6.8889, 6.1587, 4.9871,\n",
      "        2.6372, 4.0512, 2.1702, 2.5257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surfytom/Projects/Dissertation/Repos/TileEmbeddingDissertation/srcTom/Utils/Data/DataLoading.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "crossValidationData = DataLoading.LoadCrossValTrainTestData(\"../data/tomData/unshuffled3x3tiles.csv\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextTileToImage(tileArray, tileSize, spritePath, savePath=None):\n",
    "\n",
    "    outputImage = np.empty((tileSize*tileArray.shape[0], tileSize*tileArray.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    fileName = \"\"\n",
    "\n",
    "    for i, row in enumerate(tileArray):\n",
    "        for j, tile in enumerate(row):\n",
    "\n",
    "            tile = '@' if tile == '.' else tile\n",
    "            fileName += tile\n",
    "\n",
    "            tileImage = cv2.cvtColor(cv2.imread(f\"{spritePath}/{tile}.png\"), cv2.COLOR_BGR2RGB)\n",
    "            outputImage[i*tileSize:(i+1)*tileSize, j*tileSize:(j+1)*tileSize] = tileImage\n",
    "\n",
    "    if savePath:\n",
    "        cv2.imwrite(f\"{savePath}/{fileName}.png\", outputImage)\n",
    "\n",
    "    return outputImage\n",
    "\n",
    "def TFIDFWeightVector(data, uniqueClasses):\n",
    "    # Initialize TfidfVectorizer from sklearn\n",
    "    vectorizer = TfidfVectorizer(stop_words=None)\n",
    "\n",
    "    # Fit the TfidfVectorizer to affordance values in the training set\n",
    "    vectorizer.fit_transform(data[\"affordances\"].apply(lambda x: str(x)))\n",
    "\n",
    "    # Add the weights created for each affordance class to a easily indexable dictionary\n",
    "    newDict = {affordanceClass: vectorizer.idf_[vectorizer.vocabulary_[affordanceClass]] if affordanceClass in vectorizer.vocabulary_ else 0.0 for affordanceClass in uniqueClasses}\n",
    "\n",
    "    # Average each weight and scale by 1000\n",
    "    # weightFreq = {k: v / sum(newDict.values()) for k, v in newDict.items()}\n",
    "    # weightVector = [v * 1000 for v in newDict.values()] Forked github code dont know why * 1000??\n",
    "    weightVector = [v for v in newDict.values()]\n",
    "\n",
    "    tensorFromList = torch.tensor(weightVector, dtype=torch.float32)\n",
    "    print(tensorFromList)\n",
    "\n",
    "    return newDict, tensorFromList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTrainTestData(pathToDataCsv, testSetSize=0.1, shuffle=False, randomState=1):\n",
    "\n",
    "    dataFrame = pd.read_csv(pathToDataCsv)\n",
    "\n",
    "    dataFrame['affordances'] = dataFrame['affordances'].apply(lambda x: literal_eval(str(x)))\n",
    "    dataFrame['tiles'] = dataFrame['tiles'].apply(lambda x: np.array(literal_eval(str(x))))\n",
    "\n",
    "    return train_test_split(dataFrame, test_size=testSetSize, random_state=randomState, shuffle=shuffle)\n",
    "\n",
    "def LoadCrossValTrainTestData(pathToDataCsv, shuffle=False, randomState=1):\n",
    "\n",
    "    crossValDataDict = {}\n",
    "\n",
    "    spritePaths = {\n",
    "        \"kidicarus\": \"../data/tomData/sprites/kidicarus\", \n",
    "        \"loderunner\": \"../data/tomData/sprites/loderunner\",\n",
    "        \"megaman\": \"../data/tomData/sprites/megaman\",\n",
    "        \"supermariobros\": \"../data/tomData/sprites/supermariobros\",\n",
    "        \"thelegendofzelda\": \"../data/tomData/sprites/thelegendofzelda\",\n",
    "    }\n",
    "\n",
    "    dataFrame = pd.read_csv(pathToDataCsv)\n",
    "\n",
    "    dataFrame['affordances'] = dataFrame['affordances'].apply(lambda x: literal_eval(str(x)))\n",
    "    dataFrame['tiles'] = dataFrame['tiles'].apply(lambda x: np.array(literal_eval(str(x))))\n",
    "\n",
    "    dataFrame['image'] = [TextTileToImage(row['tiles'], 16, spritePaths[row['gamename']]) for index, row in dataFrame.iterrows()]\n",
    "\n",
    "    uniqueAffordances = set([affordance for affordanceList in dataFrame['affordances'] for affordance in affordanceList])\n",
    "\n",
    "    print(uniqueAffordances)\n",
    "\n",
    "    if shuffle:\n",
    "        dataFrame = dataFrame.sample(frac=1, random_state=randomState).reset_index()\n",
    "\n",
    "    for gameName in dataFrame['gamename'].unique():\n",
    "        testData = dataFrame[dataFrame['gamename'] == gameName]\n",
    "        trainData = dataFrame.drop(testData.index)\n",
    "\n",
    "        affordanceDict, tfidfWeightArray = TFIDFWeightVector(trainData, uniqueAffordances)\n",
    "\n",
    "        trainData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in trainData.iterrows()]\n",
    "        testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n",
    "        \n",
    "        crossValDataDict[gameName] = {\"trainData\": trainData, \"testData\": testData, \"weightArray\": tfidfWeightArray}\n",
    "    \n",
    "    return crossValDataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wall', 'element', 'pipe', 'passable', 'block', 'solid', 'moving', 'openable', 'hazard', 'climbable', 'collectable', 'empty', 'breakable'}\n",
      "tensor([3.6799, 3.9129, 5.4777, 1.9535, 3.4377, 1.5683, 5.0192, 4.7846, 4.4612,\n",
      "        4.9633, 5.0192, 2.0802, 4.4744])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40637/211859064.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 6.8108, 1.5074, 0.0000, 1.9175, 6.3522, 7.5223, 4.8912,\n",
      "        2.5969, 3.9553, 2.0638, 2.4590])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40637/211859064.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0217, 5.2547, 6.8195, 1.5749, 4.7795, 1.8468, 6.6372, 6.1263, 5.0308,\n",
      "        2.6287, 4.0014, 2.1699, 2.4773])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40637/211859064.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0529, 5.2859, 6.8507, 1.5881, 4.8106, 1.8553, 6.8327, 6.4272, 4.9445,\n",
      "        2.6360, 3.9953, 2.1532, 2.4989])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40637/211859064.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0540, 5.2870, 0.0000, 1.5883, 4.8118, 1.8340, 6.8889, 6.1587, 4.9871,\n",
      "        2.6372, 4.0512, 2.1702, 2.5257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40637/211859064.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(affordanceDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "# Loading standard train test split\n",
    "crossValidationData = LoadCrossValTrainTestData(\"../data/tomData/unshuffled3x3tiles.csv\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCE(nn.Module):\n",
    "\n",
    "    def __init__(self, weightedArray, debug=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        self.weighedArray = weightedArray\n",
    "\n",
    "    def forward(self, yPred, yTrue):\n",
    "\n",
    "        bce_array = nn.functional.binary_cross_entropy(yPred, yTrue, reduction=\"none\")\n",
    "        weighted_array = torch.mul(bce_array, self.weighedArray)\n",
    "\n",
    "        if self.debug:\n",
    "            print(weighted_array.shape)\n",
    "\n",
    "        bce_sum = torch.sum(weighted_array, axis=1)\n",
    "        loss = torch.div(bce_sum, 13.0)\n",
    "        loss = torch.mean(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileEmbeddingVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, debug=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        self.imageEncoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.textEncoder = nn.Sequential(\n",
    "            nn.Linear(13, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.embeddingLayer = nn.Linear(4112, 256)\n",
    "\n",
    "        self.imageDecoder = nn.Sequential(\n",
    "            nn.Linear(256, 4096),\n",
    "            nn.Unflatten(1, (16, 16, 16)),\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.textDecoder = nn.Sequential(\n",
    "            nn.Linear(256, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 13),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, xImages, xText):\n",
    "        encodedImage = self.imageEncoder(xImages)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"xText shape: {xText.shape}\")\n",
    "\n",
    "        encodedText = self.textEncoder(xText)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"EncodedImage shape: \", encodedImage.shape)\n",
    "            print(\"encodedText shape: \", encodedText.shape)\n",
    "\n",
    "        concatenateEmbeddding = torch.cat((encodedImage, encodedText), 1)\n",
    "\n",
    "        embedding = self.embeddingLayer(concatenateEmbeddding)\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def decode(self, embedding):\n",
    "        decodedImage = self.imageDecoder(embedding)\n",
    "        decodedText = self.textDecoder(embedding)\n",
    "        return decodedImage, decodedText\n",
    "\n",
    "    def forward(self, xImages, xText):\n",
    "        # Encoder\n",
    "        encodedEmbedding = self.encode(xImages, xText)\n",
    "\n",
    "        # Decoder\n",
    "        yPredImage, yPredText = self.decode(encodedEmbedding)\n",
    "        \n",
    "        return yPredImage, yPredText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def TrainModel(dataObj, epochs, batchSize):\n",
    "    # dataObj = {\"trainData\": trainingdata, \"testData\": testData, \"weightArray\": tfidfWeightArray}\n",
    "\n",
    "    model = TileEmbeddingVAE()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    imageCritierion = nn.MSELoss()\n",
    "    textCritierion = WeightedBCE(dataObj[\"weightArray\"].to(device))\n",
    "\n",
    "    imageLossWeight = 0.8\n",
    "    textLossWeight = 1.0 - imageLossWeight\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    trainData = dataObj[\"trainData\"]\n",
    "    losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        losses.append([])\n",
    "\n",
    "        for j in range(0, trainData.shape[0], batchSize):\n",
    "\n",
    "            xImages = np.array(trainData.iloc[j:j+batchSize][\"image\"].tolist())\n",
    "            yImages = xImages[:, 16:32, 16:32, :]\n",
    "            # print(xImages.shape)\n",
    "            # print(yImages.shape)\n",
    "\n",
    "            xImageBatch = torch.tensor(xImages, dtype=torch.float32)\n",
    "            xImageBatch = xImageBatch.reshape((-1, 3, 48, 48))\n",
    "            xImageBatch = xImageBatch.to(device)\n",
    "\n",
    "            yImageBatch = torch.tensor(yImages, dtype=torch.float32)\n",
    "            yImageBatch = yImageBatch.reshape((-1, 3, 16, 16))\n",
    "            yImageBatch = yImageBatch.to(device)\n",
    "            \n",
    "            xTextbatch = torch.tensor(trainData.iloc[j:j+batchSize][\"encodedAffordances\"].tolist(), dtype=torch.float32).to(device)\n",
    "\n",
    "            yPredImages, yPredTexts = model(xImageBatch, xTextbatch)\n",
    "            # print(yPredImages.shape)\n",
    "            # print(yImageBatch.shape)\n",
    "\n",
    "            imageLoss = imageCritierion(yPredImages, yImageBatch)\n",
    "            textLoss = textCritierion(yPredTexts, xTextbatch)\n",
    "            # print(imageLoss)\n",
    "            # print(textLoss)\n",
    "\n",
    "            loss = torch.add(torch.mul(imageLoss, imageLossWeight), torch.mul(textLoss, textLossWeight))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses[i].append(loss.cpu().detach().item())\n",
    "\n",
    "        print(f\"Epoch {i}: loss {sum(losses[i])/len(losses[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8106, 2.4989, 2.6360, 3.9953, 5.2859, 2.1532, 4.9445, 6.8327, 6.4272,\n",
       "        1.5881, 6.8507, 1.8553, 5.0529])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidationData[\"kidicarus\"][\"weightArray\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 6198.500048174906\n",
      "Epoch 1: loss 3306.449803176931\n",
      "Epoch 2: loss 2142.480155306915\n",
      "Epoch 3: loss 1385.9383625553603\n",
      "Epoch 4: loss 901.5092200339838\n",
      "Epoch 5: loss 578.3434430891056\n",
      "Epoch 6: loss 356.36727619490097\n",
      "Epoch 7: loss 209.0026473361114\n",
      "Epoch 8: loss 119.64031777653008\n",
      "Epoch 9: loss 66.00241887848513\n"
     ]
    }
   ],
   "source": [
    "TrainModel(crossValidationData[\"kidicarus\"], 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loderunner\n",
      "Epoch 0: loss 9428.914293791118\n",
      "Done\n",
      "thelegendofzelda\n",
      "Epoch 0: loss 6191.405737900152\n",
      "Done\n",
      "megaman\n",
      "Epoch 0: loss 5967.292700574806\n",
      "Done\n",
      "kidicarus\n",
      "Epoch 0: loss 6195.930823692908\n",
      "Done\n",
      "supermariobros\n",
      "Epoch 0: loss 6297.045042720527\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for k, v in crossValidationData.items():\n",
    "    print(k)\n",
    "    TrainModel(v, 1, 32)\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DissEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
