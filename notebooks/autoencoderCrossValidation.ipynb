{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTrainTestData(pathToDataCsv, testSetSize=0.1, shuffle=False, randomState=1):\n",
    "\n",
    "    dataFrame = pd.read_csv(pathToDataCsv)\n",
    "\n",
    "    dataFrame['affordances'] = dataFrame['affordances'].apply(lambda x: literal_eval(str(x)))\n",
    "    dataFrame['tiles'] = dataFrame['tiles'].apply(lambda x: np.array(literal_eval(str(x))))\n",
    "\n",
    "    return train_test_split(dataFrame, test_size=testSetSize, random_state=randomState, shuffle=shuffle)\n",
    "\n",
    "def LoadCrossValTrainTestData(pathToDataCsv, shuffle=False, randomState=1):\n",
    "\n",
    "    crossValDataDict = {}\n",
    "\n",
    "    dataFrame = pd.read_csv(pathToDataCsv)\n",
    "\n",
    "    dataFrame['affordances'] = dataFrame['affordances'].apply(lambda x: literal_eval(str(x)))\n",
    "    dataFrame['tiles'] = dataFrame['tiles'].apply(lambda x: np.array(literal_eval(str(x))))\n",
    "\n",
    "    if shuffle:\n",
    "        dataFrame = dataFrame.sample(frac=1, random_state=randomState).reset_index()\n",
    "\n",
    "    for gameName in dataFrame['gamename'].unique():\n",
    "        testData = dataFrame[dataFrame['gamename'] == gameName]\n",
    "        trainData = dataFrame.drop(testData.index)\n",
    "        \n",
    "        crossValDataDict[gameName] = {\"trainData\": trainData, \"testData\": testData}\n",
    "    \n",
    "    return crossValDataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading standard train test split\n",
    "trainData, testData = LoadTrainTestData(\"../data/tomData/unshuffled3x3tiles.csv\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextTileToImage(tileArray, tileSize, spritePath, savePath=None):\n",
    "\n",
    "    outputImage = np.empty((tileSize*tileArray.shape[0], tileSize*tileArray.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    fileName = \"\"\n",
    "\n",
    "    for i, row in enumerate(tileArray):\n",
    "        for j, tile in enumerate(row):\n",
    "\n",
    "            tile = '@' if tile == '.' else tile\n",
    "            fileName += tile\n",
    "\n",
    "            tileImage = cv2.cvtColor(cv2.imread(f\"{spritePath}/{tile}.png\"), cv2.COLOR_BGR2RGB)\n",
    "            outputImage[i*tileSize:(i+1)*tileSize, j*tileSize:(j+1)*tileSize] = tileImage\n",
    "\n",
    "    if savePath:\n",
    "        cv2.imwrite(f\"{savePath}/{fileName}.png\", outputImage)\n",
    "\n",
    "    return outputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spritePaths = {\n",
    "    \"kidicarus\": \"../data/tomData/sprites/kidicarus\", \n",
    "    \"loderunner\": \"../data/tomData/sprites/loderunner\",\n",
    "    \"megaman\": \"../data/tomData/sprites/megaman\",\n",
    "    \"supermariobros\": \"../data/tomData/sprites/supermariobros\",\n",
    "    \"thelegendofzelda\": \"../data/tomData/sprites/thelegendofzelda\",\n",
    "}\n",
    "\n",
    "# Does the same thing as above but faster\n",
    "trainData[\"image\"] = [TextTileToImage(row['tiles'], 16, spritePaths[row['gamename']]) for index, row in trainData.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer from sklearn\n",
    "vectorizer = TfidfVectorizer(stop_words=None)\n",
    "\n",
    "# Find all unique affordance values\n",
    "flattendedAffordanceList = []\n",
    "for affordanceList in trainData['affordances'].to_list():\n",
    "    flattendedAffordanceList += affordanceList\n",
    "affordanceClasses = np.unique(np.array(flattendedAffordanceList))\n",
    "\n",
    "# Fit the TfidfVectorizer to affordance values in the training set\n",
    "vectorizer.fit_transform(trainData[\"affordances\"].apply(lambda x: str(x)))\n",
    "\n",
    "# Add the weights created for each affordance class to a easily indexable dictionary\n",
    "newDict = {affordanceClass: vectorizer.idf_[vectorizer.vocabulary_[affordanceClass]] for affordanceClass in affordanceClasses}\n",
    "\n",
    "# Average each weight and scale by 1000\n",
    "weightFreq = {k: v / sum(newDict.values()) for k, v in newDict.items()}\n",
    "# weightVector = [v * 1000 for v in newDict.values()] Forked github code dont know why * 1000??\n",
    "weightVector = [v for v in newDict.values()]\n",
    "\n",
    "\n",
    "tensorFromList = torch.tensor(weightVector, dtype=torch.float32)\n",
    "print(tensorFromList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the same thing as above but faster\n",
    "trainData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(newDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in trainData.iterrows()]\n",
    "testData[\"encodedAffordances\"] = [np.sum(np.array([np.where(np.array(list(newDict.keys())) == affordance, 1, 0) for affordance in row['affordances']]), axis=0) for index, row in testData.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCE(nn.Module):\n",
    "\n",
    "    def __init__(self, weightedArray, debug=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        self.weighedArray = weightedArray\n",
    "\n",
    "    def forward(self, yPred, yTrue):\n",
    "\n",
    "        bce_array = nn.functional.binary_cross_entropy(yPred, yTrue, reduction=\"none\")\n",
    "        weighted_array = torch.mul(bce_array, self.weighedArray)\n",
    "\n",
    "        if self.debug:\n",
    "            print(weighted_array.shape)\n",
    "\n",
    "        bce_sum = torch.sum(weighted_array, axis=1)\n",
    "        loss = torch.div(bce_sum, 13.0)\n",
    "        loss = torch.mean(loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileEmbeddingVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, debug=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        self.imageEncoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.textEncoder = nn.Sequential(\n",
    "            nn.Linear(13, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.embeddingLayer = nn.Linear(4112, 256)\n",
    "\n",
    "        self.imageDecoder = nn.Sequential(\n",
    "            nn.Linear(256, 4096),\n",
    "            nn.Unflatten(1, (16, 16, 16)),\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.textDecoder = nn.Sequential(\n",
    "            nn.Linear(256, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 13),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, xImages, xText):\n",
    "        encodedImage = self.imageEncoder(xImages)\n",
    "        encodedText = self.textEncoder(xText)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"EncodedImage shape: \", encodedImage.shape)\n",
    "            print(\"encodedText shape: \", encodedText.shape)\n",
    "\n",
    "        concatenateEmbeddding = torch.cat((encodedImage, encodedText), 1)\n",
    "\n",
    "        embedding = self.embeddingLayer(concatenateEmbeddding)\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def decode(self, embedding):\n",
    "        decodedImage = self.imageDecoder(embedding)\n",
    "        decodedText = self.textDecoder(embedding)\n",
    "        return decodedImage, decodedText\n",
    "\n",
    "    def forward(self, xImages, xText):\n",
    "        # Encoder\n",
    "        encodedEmbedding = self.encode(xImages, xText)\n",
    "\n",
    "        # Decoder\n",
    "        yPredImage, yPredText = self.decode(encodedEmbedding)\n",
    "        \n",
    "        return yPredImage, yPredText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TileEmbeddingVAE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "imageCritierion = nn.MSELoss()\n",
    "textCritierion = WeightedBCE(tensorFromList.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "epochs = 1\n",
    "\n",
    "imageLossWeight = 0.8\n",
    "textLossWeight = 1.0 - imageLossWeight\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for j in range(0, trainData.shape[0], batchSize):\n",
    "\n",
    "        xImages = np.array(trainData.iloc[j:j+batchSize][\"image\"].tolist())\n",
    "        yImages = xImages[:, 16:32, 16:32, :]\n",
    "        # print(xImages.shape)\n",
    "        # print(yImages.shape)\n",
    "\n",
    "        xImageBatch = torch.tensor(xImages, dtype=torch.float32)\n",
    "        xImageBatch = xImageBatch.reshape((-1, 3, 48, 48))\n",
    "        xImageBatch = xImageBatch.to(device)\n",
    "\n",
    "        yImageBatch = torch.tensor(yImages, dtype=torch.float32)\n",
    "        yImageBatch = yImageBatch.reshape((-1, 3, 16, 16))\n",
    "        yImageBatch = yImageBatch.to(device)\n",
    "        \n",
    "        xTextbatch = torch.tensor(trainData.iloc[j:j+batchSize][\"encodedAffordances\"].tolist(), dtype=torch.float32).to(device)\n",
    "\n",
    "        yPredImages, yPredTexts = model(xImageBatch, xTextbatch)\n",
    "        # print(yPredImages.shape)\n",
    "        # print(yImageBatch.shape)\n",
    "\n",
    "        imageLoss = imageCritierion(yPredImages, yImageBatch)\n",
    "        textLoss = textCritierion(yPredTexts, xTextbatch)\n",
    "        # print(imageLoss)\n",
    "        # print(textLoss)\n",
    "\n",
    "        loss = torch.add(torch.mul(imageLoss, imageLossWeight), torch.mul(textLoss, textLossWeight))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.cpu().detach().item())\n",
    "\n",
    "    print(f\"Epoch {i}: loss {sum(losses)/len(losses)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DissEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
