{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pregnant-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.utils import shuffle\\nimport json\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\nfrom keras.models import model_from_json\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.utils import shuffle\\nimport json\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\nfrom keras.models import model_from_json\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "from evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "\n",
    "from evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from data_loading.load_data import get_tile_data\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alternate-butterfly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games detected in the parent folder ['lode_runner', 'kid_icarus', 'megaman', 'smb', 'loz']\n",
      "Current Game lode_runner\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/lode_runner\n",
      "Current Game kid_icarus\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/kid_icarus\n",
      "Current Game megaman\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/megaman\n",
      "Current Game smb\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/smb\n",
      "Current Game loz\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/loz\n",
      "\n",
      "The size of total data is (25394, 5)\n",
      "\n",
      "The size of the train data is  (22854, 5)\n",
      "The size of the test data is  (2540, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"##loading train and testing data\\n\\ndata_directory = \\\"../data/context_data/\\\"\\njson_directory = \\\"../data/json_files_trimmed_features/\\\"\\ndata = get_tile_data(data_directory, json_directory)\\nprint(\\\"\\\\nThe size of total data is\\\", data.shape)\\ndata = shuffle(data)\\n\\n# split into train-test\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\\n\\nprint(\\\"\\\\nThe size of the train data is \\\", train_data.shape)\\nprint(\\\"The size of the test data is \\\", test_data.shape)\";\n",
       "                var nbb_formatted_code = \"##loading train and testing data\\n\\ndata_directory = \\\"../data/context_data/\\\"\\njson_directory = \\\"../data/json_files_trimmed_features/\\\"\\ndata = get_tile_data(data_directory, json_directory)\\nprint(\\\"\\\\nThe size of total data is\\\", data.shape)\\ndata = shuffle(data)\\n\\n# split into train-test\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\\n\\nprint(\\\"\\\\nThe size of the train data is \\\", train_data.shape)\\nprint(\\\"The size of the test data is \\\", test_data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##loading train and testing data\n",
    "\n",
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "data = get_tile_data(data_directory, json_directory)\n",
    "print(\"\\nThe size of total data is\", data.shape)\n",
    "data = shuffle(data)\n",
    "\n",
    "# split into train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\n",
    "\n",
    "print(\"\\nThe size of the train data is \", train_data.shape)\n",
    "print(\"The size of the test data is \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "premium-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dictionary Loaded\n",
      "The feature dictionary has size 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['block', 'breakable', 'climbable', 'collectable', 'element',\n",
       "       'empty', 'hazard', 'moving', 'openable', 'passable', 'pipe',\n",
       "       'solid', 'wall'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Entire Autoencoder Model from the Disk\n",
      "Loaded Encoder Model from the Disk\n",
      "Loaded Decoder Model from the Disk\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# load the multilabel binarizer\\nimport pickle\\n\\nwith open(\\\"model_tokenizer.pickle\\\", \\\"rb\\\") as handle:\\n    mlb = pickle.load(handle)\\nprint(\\\"Feature Dictionary Loaded\\\")\\ntotal_features = len(mlb.classes_)\\nprint(\\\"The feature dictionary has size\\\", total_features)\\ndisplay(\\\"Features\\\", mlb.classes_)\\n\\n# load entire autoencoder architecture\\njson_file = open(\\\"autoencoder_model.json\\\", \\\"r\\\")\\nloaded_model_json = json_file.read()\\njson_file.close()\\nae_sep_output = model_from_json(loaded_model_json)\\nae_sep_output.load_weights(\\\"autoencoder_model.h5\\\")\\nprint(\\\"Loaded Entire Autoencoder Model from the Disk\\\")\\n\\n# load the encoding architecture and weights\\njson_file = open(\\\"encoder_model.json\\\", \\\"r\\\")\\nloaded_model_json = json_file.read()\\njson_file.close()\\nencoding_model = model_from_json(loaded_model_json)\\nencoding_model.load_weights(\\\"encoder_model.h5\\\")\\nprint(\\\"Loaded Encoder Model from the Disk\\\")\\n\\n# load the decoding architecture and weights\\njson_file = open(\\\"decoder_model.json\\\", \\\"r\\\")\\nloaded_model_json = json_file.read()\\njson_file.close()\\ndecoding_model = model_from_json(loaded_model_json)\\n# load weights into new model\\ndecoding_model.load_weights(\\\"decoder_model.h5\\\")\\nprint(\\\"Loaded Decoder Model from the Disk\\\")\";\n",
       "                var nbb_formatted_code = \"# load the multilabel binarizer\\nimport pickle\\n\\nwith open(\\\"model_tokenizer.pickle\\\", \\\"rb\\\") as handle:\\n    mlb = pickle.load(handle)\\nprint(\\\"Feature Dictionary Loaded\\\")\\ntotal_features = len(mlb.classes_)\\nprint(\\\"The feature dictionary has size\\\", total_features)\\ndisplay(\\\"Features\\\", mlb.classes_)\\n\\n# load entire autoencoder architecture\\njson_file = open(\\\"autoencoder_model.json\\\", \\\"r\\\")\\nloaded_model_json = json_file.read()\\njson_file.close()\\nae_sep_output = model_from_json(loaded_model_json)\\nae_sep_output.load_weights(\\\"autoencoder_model.h5\\\")\\nprint(\\\"Loaded Entire Autoencoder Model from the Disk\\\")\\n\\n# load the encoding architecture and weights\\njson_file = open(\\\"encoder_model.json\\\", \\\"r\\\")\\nloaded_model_json = json_file.read()\\njson_file.close()\\nencoding_model = model_from_json(loaded_model_json)\\nencoding_model.load_weights(\\\"encoder_model.h5\\\")\\nprint(\\\"Loaded Encoder Model from the Disk\\\")\\n\\n# load the decoding architecture and weights\\njson_file = open(\\\"decoder_model.json\\\", \\\"r\\\")\\nloaded_model_json = json_file.read()\\njson_file.close()\\ndecoding_model = model_from_json(loaded_model_json)\\n# load weights into new model\\ndecoding_model.load_weights(\\\"decoder_model.h5\\\")\\nprint(\\\"Loaded Decoder Model from the Disk\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the multilabel binarizer\n",
    "import pickle\n",
    "\n",
    "with open(\"model_tokenizer.pickle\", \"rb\") as handle:\n",
    "    mlb = pickle.load(handle)\n",
    "print(\"Feature Dictionary Loaded\")\n",
    "total_features = len(mlb.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "display(\"Features\", mlb.classes_)\n",
    "\n",
    "# load entire autoencoder architecture\n",
    "json_file = open(\"autoencoder_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "ae_sep_output = model_from_json(loaded_model_json)\n",
    "ae_sep_output.load_weights(\"autoencoder_model.h5\")\n",
    "print(\"Loaded Entire Autoencoder Model from the Disk\")\n",
    "\n",
    "# load the encoding architecture and weights\n",
    "json_file = open(\"encoder_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_model = model_from_json(loaded_model_json)\n",
    "encoding_model.load_weights(\"encoder_model.h5\")\n",
    "print(\"Loaded Encoder Model from the Disk\")\n",
    "\n",
    "# load the decoding architecture and weights\n",
    "json_file = open(\"decoder_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "decoding_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "decoding_model.load_weights(\"decoder_model.h5\")\n",
    "print(\"Loaded Decoder Model from the Disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "social-integrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Batches\n",
      "Training Data Ready\n",
      "Train Image batch shape (22854, 48, 48, 3)\n",
      "Train Text batch shape (22854, 13)\n",
      "Output Image batch shape (22854, 16, 16, 3)\n",
      "Output Text batch shape (22854, 13)\n",
      "Building Testing Batches\n",
      "\n",
      "\n",
      "Testing Data Ready\n",
      "Train Image batch shape (2540, 48, 48, 3)\n",
      "Train Text batch shape (2540, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Build Input Output Training Batches\\nprint(\\\"Building Training Batches\\\")\\n\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntrain_image_batch = []\\nfor train_path in train_data[\\\"image_path\\\"]:\\n    tile = image.load_img(train_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    train_image_batch.append(tile_sprite)\\ntrain_image_batch = np.array(train_image_batch)\\ntrain_text_batch = []\\nfor i in range(len(train_data[\\\"features\\\"])):\\n    text_ = mlb.transform(train_data[\\\"features\\\"][i : i + 1])\\n    train_text_batch.append(text_)\\ntrain_text_batch = np.array(train_text_batch).reshape(\\n    train_data.shape[0], total_features\\n)\\n\\noutput_image_batch = []\\nfor i in range(len(train_image_batch)):\\n    current_image = train_image_batch[i]\\n    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    output_image_batch.append(current_image_centre)\\noutput_image_batch = np.array(output_image_batch)\\noutput_text_batch = []\\nfor i in range(len(train_text_batch)):\\n    current_text = train_text_batch[i]\\n    output_text_batch.append(current_text)\\noutput_text_batch = np.array(output_text_batch)\\nprint(\\\"Training Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", train_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", train_text_batch.shape)\\nprint(\\\"Output Image batch shape\\\", output_image_batch.shape)\\nprint(\\\"Output Text batch shape\\\", output_text_batch.shape)\\n\\n\\n# Build Input Output Test Batches\\nprint(\\\"Building Testing Batches\\\")\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntest_image_batch = []\\nfor test_path in test_data[\\\"image_path\\\"]:\\n    tile = image.load_img(test_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    test_image_batch.append(tile_sprite)\\ntest_image_batch = np.array(test_image_batch)\\ntest_text_batch = []\\nfor i in range(len(test_data[\\\"features\\\"])):\\n    text_ = mlb.transform(test_data[\\\"features\\\"][i : i + 1])\\n    test_text_batch.append(text_)\\ntest_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\\nprint(\\\"\\\\n\\\\nTesting Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", test_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", test_text_batch.shape)\";\n",
       "                var nbb_formatted_code = \"# Build Input Output Training Batches\\nprint(\\\"Building Training Batches\\\")\\n\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntrain_image_batch = []\\nfor train_path in train_data[\\\"image_path\\\"]:\\n    tile = image.load_img(train_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    train_image_batch.append(tile_sprite)\\ntrain_image_batch = np.array(train_image_batch)\\ntrain_text_batch = []\\nfor i in range(len(train_data[\\\"features\\\"])):\\n    text_ = mlb.transform(train_data[\\\"features\\\"][i : i + 1])\\n    train_text_batch.append(text_)\\ntrain_text_batch = np.array(train_text_batch).reshape(\\n    train_data.shape[0], total_features\\n)\\n\\noutput_image_batch = []\\nfor i in range(len(train_image_batch)):\\n    current_image = train_image_batch[i]\\n    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    output_image_batch.append(current_image_centre)\\noutput_image_batch = np.array(output_image_batch)\\noutput_text_batch = []\\nfor i in range(len(train_text_batch)):\\n    current_text = train_text_batch[i]\\n    output_text_batch.append(current_text)\\noutput_text_batch = np.array(output_text_batch)\\nprint(\\\"Training Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", train_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", train_text_batch.shape)\\nprint(\\\"Output Image batch shape\\\", output_image_batch.shape)\\nprint(\\\"Output Text batch shape\\\", output_text_batch.shape)\\n\\n\\n# Build Input Output Test Batches\\nprint(\\\"Building Testing Batches\\\")\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntest_image_batch = []\\nfor test_path in test_data[\\\"image_path\\\"]:\\n    tile = image.load_img(test_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    test_image_batch.append(tile_sprite)\\ntest_image_batch = np.array(test_image_batch)\\ntest_text_batch = []\\nfor i in range(len(test_data[\\\"features\\\"])):\\n    text_ = mlb.transform(test_data[\\\"features\\\"][i : i + 1])\\n    test_text_batch.append(text_)\\ntest_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\\nprint(\\\"\\\\n\\\\nTesting Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", test_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", test_text_batch.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Input Output Training Batches\n",
    "print(\"Building Training Batches\")\n",
    "\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "train_image_batch = []\n",
    "for train_path in train_data[\"image_path\"]:\n",
    "    tile = image.load_img(train_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    train_image_batch.append(tile_sprite)\n",
    "train_image_batch = np.array(train_image_batch)\n",
    "train_text_batch = []\n",
    "for i in range(len(train_data[\"features\"])):\n",
    "    text_ = mlb.transform(train_data[\"features\"][i : i + 1])\n",
    "    train_text_batch.append(text_)\n",
    "train_text_batch = np.array(train_text_batch).reshape(\n",
    "    train_data.shape[0], total_features\n",
    ")\n",
    "\n",
    "output_image_batch = []\n",
    "for i in range(len(train_image_batch)):\n",
    "    current_image = train_image_batch[i]\n",
    "    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    output_image_batch.append(current_image_centre)\n",
    "output_image_batch = np.array(output_image_batch)\n",
    "output_text_batch = []\n",
    "for i in range(len(train_text_batch)):\n",
    "    current_text = train_text_batch[i]\n",
    "    output_text_batch.append(current_text)\n",
    "output_text_batch = np.array(output_text_batch)\n",
    "print(\"Training Data Ready\")\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "\n",
    "# Build Input Output Test Batches\n",
    "print(\"Building Testing Batches\")\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "test_image_batch = []\n",
    "for test_path in test_data[\"image_path\"]:\n",
    "    tile = image.load_img(test_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    test_image_batch.append(tile_sprite)\n",
    "test_image_batch = np.array(test_image_batch)\n",
    "test_text_batch = []\n",
    "for i in range(len(test_data[\"features\"])):\n",
    "    text_ = mlb.transform(test_data[\"features\"][i : i + 1])\n",
    "    test_text_batch.append(text_)\n",
    "test_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\n",
    "print(\"\\n\\nTesting Data Ready\")\n",
    "print(\"Train Image batch shape\", test_image_batch.shape)\n",
    "print(\"Train Text batch shape\", test_text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-eclipse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radio-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y is Ready. Shape :  (2540, 13)\n",
      "True Y is Ready. Shape : (2540, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"predicted_image, predicted_text = ae_sep_output.predict(\\n    [test_image_batch, test_text_batch]\\n)\\ny_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\\ny_pred = np.array(y_pred)\\nprint(\\\"Predicted Y is Ready. Shape : \\\", y_pred.shape)\\n\\ny_true = test_text_batch\\ny_true = np.array(y_true)\\nprint(\\\"True Y is Ready. Shape :\\\", y_true.shape)\";\n",
       "                var nbb_formatted_code = \"predicted_image, predicted_text = ae_sep_output.predict(\\n    [test_image_batch, test_text_batch]\\n)\\ny_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\\ny_pred = np.array(y_pred)\\nprint(\\\"Predicted Y is Ready. Shape : \\\", y_pred.shape)\\n\\ny_true = test_text_batch\\ny_true = np.array(y_true)\\nprint(\\\"True Y is Ready. Shape :\\\", y_true.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "south-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Array shape  (2540, 16, 16, 3)\n",
      "True Array shape  (2540, 16, 16, 3)\n",
      "Mean MSE 266.4628\n",
      "Median MSE 36.328003\n",
      "\n",
      "Macro Label Based Precision 0.9997858647027486\n",
      "Macro Label Based Recall 0.9941111330011694\n",
      "Macro Label Based Accuracy 0.9938972253123506\n",
      "\n",
      "Micro Label Based Precision 0.9993521917512417\n",
      "Micro Label Based Recall 0.998705222270177\n",
      "Micro Label Based Accuracy 0.9980590899288333\n",
      "\n",
      "Example Based Precision 0.9994094488188976\n",
      "Example Based Recall 0.9990157480314961\n",
      "Example Based Accuracy 0.9986876640419947\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"true_image = []\\nfor i in range(len(test_image_batch)):\\n    current_image = test_image_batch[i]\\n    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    true_image.append(current_image_centre)\\ntrue_image = np.array(true_image)\\nprint(\\\"Predicted Array shape \\\", predicted_image.shape)\\nprint(\\\"True Array shape \\\", true_image.shape)\\n\\nmse_dist = []\\nfor idx in range(len(true_image)):\\n    y_true_image = true_image[idx]\\n    y_true_image = y_true_image.reshape(16, 16, 3)\\n\\n    y_pred_image = predicted_image[idx]\\n    y_pred_image = y_pred_image.reshape(16, 16, 3)\\n\\n    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\\n\\nprint(\\\"Mean MSE\\\", np.mean(mse_dist))\\nprint(\\\"Median MSE\\\", np.median(mse_dist))\\n\\ndef valid_divide(num, den):\\n    count = 0\\n    result = {}\\n    for idx in range(len(num)):\\n        if num[idx] == den[idx] == 0:\\n            continue\\n        elif num[idx] != 0 and den[idx] != 0:\\n            result[idx] = num[idx] / den[idx]\\n            count += 1\\n        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\\n            count += 1\\n            result[idx] = 0.0\\n    return result, count\\n\\nprint(\\\"\\\\nMacro Label Based Precision\\\", precision_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Recall\\\", recall_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Accuracy\\\", accuracy_macro(y_true, y_pred))\\n\\nprint(\\\"\\\\nMicro Label Based Precision\\\", precision_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Recall\\\", recall_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Accuracy\\\", accuracy_micro(y_true, y_pred))\\n\\nprint(\\\"\\\\nExample Based Precision\\\", example_based_precision(y_true, y_pred))\\nprint(\\\"Example Based Recall\\\", example_based_recall(y_true, y_pred))\\nprint(\\\"Example Based Accuracy\\\", example_based_accuracy(y_true, y_pred))\";\n",
       "                var nbb_formatted_code = \"true_image = []\\nfor i in range(len(test_image_batch)):\\n    current_image = test_image_batch[i]\\n    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    true_image.append(current_image_centre)\\ntrue_image = np.array(true_image)\\nprint(\\\"Predicted Array shape \\\", predicted_image.shape)\\nprint(\\\"True Array shape \\\", true_image.shape)\\n\\nmse_dist = []\\nfor idx in range(len(true_image)):\\n    y_true_image = true_image[idx]\\n    y_true_image = y_true_image.reshape(16, 16, 3)\\n\\n    y_pred_image = predicted_image[idx]\\n    y_pred_image = y_pred_image.reshape(16, 16, 3)\\n\\n    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\\n\\nprint(\\\"Mean MSE\\\", np.mean(mse_dist))\\nprint(\\\"Median MSE\\\", np.median(mse_dist))\\n\\n\\ndef valid_divide(num, den):\\n    count = 0\\n    result = {}\\n    for idx in range(len(num)):\\n        if num[idx] == den[idx] == 0:\\n            continue\\n        elif num[idx] != 0 and den[idx] != 0:\\n            result[idx] = num[idx] / den[idx]\\n            count += 1\\n        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\\n            count += 1\\n            result[idx] = 0.0\\n    return result, count\\n\\n\\nprint(\\\"\\\\nMacro Label Based Precision\\\", precision_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Recall\\\", recall_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Accuracy\\\", accuracy_macro(y_true, y_pred))\\n\\nprint(\\\"\\\\nMicro Label Based Precision\\\", precision_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Recall\\\", recall_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Accuracy\\\", accuracy_micro(y_true, y_pred))\\n\\nprint(\\\"\\\\nExample Based Precision\\\", example_based_precision(y_true, y_pred))\\nprint(\\\"Example Based Recall\\\", example_based_recall(y_true, y_pred))\\nprint(\\\"Example Based Accuracy\\\", example_based_accuracy(y_true, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))\n",
    "\n",
    "\n",
    "def valid_divide(num, den):\n",
    "    count = 0\n",
    "    result = {}\n",
    "    for idx in range(len(num)):\n",
    "        if num[idx] == den[idx] == 0:\n",
    "            continue\n",
    "        elif num[idx] != 0 and den[idx] != 0:\n",
    "            result[idx] = num[idx] / den[idx]\n",
    "            count += 1\n",
    "        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\n",
    "            count += 1\n",
    "            result[idx] = 0.0\n",
    "    return result, count\n",
    "\n",
    "\n",
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-encoding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_representation",
   "language": "python",
   "name": "tile_representation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
