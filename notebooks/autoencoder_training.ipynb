{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atomic-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nfrom sklearn.utils import shuffle\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom notebook_utils import initialize_environment\\n\\ninitialize_environment()\\n\\nfrom utils.evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom utils.data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nfrom sklearn.utils import shuffle\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom notebook_utils import initialize_environment\\n\\ninitialize_environment()\\n\\nfrom utils.evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom utils.data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "from notebook_utils import initialize_environment\n",
    "\n",
    "initialize_environment()\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from utils.data_loading.load_data import get_tile_data\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-speech",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##loading train and testing data\n",
    "\n",
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "data = get_tile_data(data_directory, json_directory)\n",
    "print(\"\\nThe size of total data is\", data.shape)\n",
    "data = shuffle(data)\n",
    "\n",
    "# split into train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\n",
    "\n",
    "print(\"\\nThe size of the train data is \", train_data.shape)\n",
    "print(\"The size of the test data is \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Dictionary\n",
    "print(\"Building feature Dictionary..\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "combined_features = np.concatenate(\n",
    "    [train_data[\"features\"], test_data[\"features\"]], axis=0\n",
    ")\n",
    "mlb_model = mlb.fit(combined_features)\n",
    "total_features = len(mlb_model.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "print(\"Printing Feature classes\")\n",
    "display(mlb_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Input Output Training Batches\n",
    "print(\"Building Training Batches\")\n",
    "\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "train_image_batch = []\n",
    "for train_path in train_data[\"image_path\"]:\n",
    "    tile = image.load_img(train_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    train_image_batch.append(tile_sprite)\n",
    "train_image_batch = np.array(train_image_batch)\n",
    "train_text_batch = []\n",
    "for i in range(len(train_data[\"features\"])):\n",
    "    text_ = mlb.transform(train_data[\"features\"][i : i + 1])\n",
    "    train_text_batch.append(text_)\n",
    "train_text_batch = np.array(train_text_batch).reshape(\n",
    "    train_data.shape[0], total_features\n",
    ")\n",
    "\n",
    "output_image_batch = []\n",
    "for i in range(len(train_image_batch)):\n",
    "    current_image = train_image_batch[i]\n",
    "    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    output_image_batch.append(current_image_centre)\n",
    "output_image_batch = np.array(output_image_batch)\n",
    "output_text_batch = []\n",
    "for i in range(len(train_text_batch)):\n",
    "    current_text = train_text_batch[i]\n",
    "    output_text_batch.append(current_text)\n",
    "output_text_batch = np.array(output_text_batch)\n",
    "print(\"Training Data Ready\")\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "\n",
    "# Build Input Output Test Batches\n",
    "print(\"Building Testing Batches\")\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "test_image_batch = []\n",
    "for test_path in test_data[\"image_path\"]:\n",
    "    tile = image.load_img(test_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    test_image_batch.append(tile_sprite)\n",
    "test_image_batch = np.array(test_image_batch)\n",
    "test_text_batch = []\n",
    "for i in range(len(test_data[\"features\"])):\n",
    "    text_ = mlb.transform(test_data[\"features\"][i : i + 1])\n",
    "    test_text_batch.append(text_)\n",
    "test_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\n",
    "print(\"\\n\\nTesting Data Ready\")\n",
    "print(\"Train Image batch shape\", test_image_batch.shape)\n",
    "print(\"Train Text batch shape\", test_text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "latent_dim = 128\n",
    "batch_size = 1\n",
    "\n",
    "# image encoder\n",
    "image_encoder_input = Input(shape=(48, 48, 3), name=\"image_input\")\n",
    "\n",
    "image_encoder_conv_layer1 = Conv2D(\n",
    "    32, strides=3, kernel_size=(3, 3), name=\"iencode_conv1\"\n",
    ")(image_encoder_input)\n",
    "image_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\n",
    "image_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\n",
    "\n",
    "image_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\"same\", name=\"iencode_conv2\")(\n",
    "    image_encoder_actv_layer1\n",
    ")\n",
    "image_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\n",
    "image_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\n",
    "\n",
    "image_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\"same\", name=\"iencode_conv3\")(\n",
    "    image_encoder_actv_layer2\n",
    ")\n",
    "image_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\n",
    "image_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\n",
    "\n",
    "image_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\n",
    "image_flatten = Flatten(name=\"image_flatten_layer\")(image_encoder_actv_layer3)\n",
    "\n",
    "\n",
    "# text encoder\n",
    "text_encoder_input = Input(shape=(13,))\n",
    "\n",
    "text_encoder_dense_layer1 = Dense(32, activation=\"tanh\", name=\"tencode_dense1\")(\n",
    "    text_encoder_input\n",
    ")\n",
    "text_encoder_dense_layer2 = Dense(16, activation=\"tanh\", name=\"tencode_dense2\")(\n",
    "    text_encoder_dense_layer1\n",
    ")\n",
    "text_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\n",
    "\n",
    "# image-text concatenation\n",
    "image_text_concat = Concatenate(name=\"image_text_concatenation\")(\n",
    "    [image_flatten, text_encoder_dense_layer2]\n",
    ")\n",
    "\n",
    "image_text_concat = Dense(256, activation=\"tanh\", name=\"embedding_dense_1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "\n",
    "\n",
    "##\n",
    "encoding_model = Model(\n",
    "    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\n",
    ")\n",
    "\n",
    "# decoder for image\n",
    "\n",
    "# decoder_input=Input(shape=(512,))\n",
    "\n",
    "image_y = Dense(units=np.prod(image_shape_before_flatten), name=\"image_dense\")(\n",
    "    image_text_concat\n",
    ")\n",
    "image_y = Reshape(target_shape=image_shape_before_flatten, name=\"image_reshape\")(\n",
    "    image_y\n",
    ")\n",
    "\n",
    "image_decoder_convt_layer1 = Conv2DTranspose(\n",
    "    16, (3, 3), padding=\"same\", name=\"idecode_conv1\"\n",
    ")(image_y)\n",
    "image_decoder_norm_layer1 = BatchNormalization(name=\"idecode_norm1\")(\n",
    "    image_decoder_convt_layer1\n",
    ")\n",
    "image_decoder_actv_layer1 = ReLU(name=\"idecode_relu1\")(image_decoder_norm_layer1)\n",
    "\n",
    "\n",
    "image_decoder_convt_layer2 = Conv2DTranspose(\n",
    "    32, (3, 3), padding=\"same\", name=\"idecode_conv2\"\n",
    ")(image_decoder_actv_layer1)\n",
    "image_decoder_norm_layer2 = BatchNormalization(name=\"idecode_norm2\")(\n",
    "    image_decoder_convt_layer2\n",
    ")\n",
    "image_decoder_actv_layer2 = ReLU(name=\"idecode_relu2\")(image_decoder_norm_layer2)\n",
    "\n",
    "image_decoder_output = Conv2DTranspose(\n",
    "    3, (3, 3), padding=\"same\", name=\"image_output_layer\"\n",
    ")(image_decoder_actv_layer2)\n",
    "\n",
    "\n",
    "# decoder for text\n",
    "\n",
    "text_decoder_dense_layer1 = Dense(16, activation=\"tanh\", name=\"tdecode_dense1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "text_reshape = Reshape(target_shape=text_shape_before_concat, name=\"text_reshape\")(\n",
    "    text_decoder_dense_layer1\n",
    ")\n",
    "text_decoder_dense_layer2 = Dense(32, activation=\"tanh\", name=\"tdecode_dense2\")(\n",
    "    text_reshape\n",
    ")\n",
    "\n",
    "text_decoder_output = Dense(13, activation=\"sigmoid\", name=\"text_output_layer\")(\n",
    "    text_decoder_dense_layer2\n",
    ")\n",
    "\n",
    "\n",
    "# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\n",
    "\n",
    "\n",
    "ae_sep_output = Model(\n",
    "    [image_encoder_input, text_encoder_input],\n",
    "    [image_decoder_output, text_decoder_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-newsletter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae_sep_output.get_layer(\"tdecode_dense1\")\n",
    "print(ae_sep_output.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "import tensorflow as tf\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=None)\n",
    "train_data_copy = train_data\n",
    "train_data_copy[\"features\"] = train_data_copy.features.apply(lambda x: str(x))\n",
    "vectors = vectorizer.fit_transform(train_data_copy[\"features\"])\n",
    "\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "# build the weight dictionary\n",
    "new_dict = {}\n",
    "for c in mlb.classes_:\n",
    "    if c in vectorizer.vocabulary_.keys():\n",
    "        new_dict[c] = idf[vectorizer.vocabulary_[c]]\n",
    "    else:\n",
    "        new_dict[c] = np.max(idf)\n",
    "print(\"\\n Printing the TF-IDF for the labels\\n\\n\", new_dict)\n",
    "\n",
    "\n",
    "weight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\n",
    "\n",
    "print(\"\\nPrinting the weight normalised\\n\\n\")\n",
    "print(weight_freq)\n",
    "\n",
    "weight_vector = [v * 1000 for v in new_dict.values()]\n",
    "\n",
    "tensor_from_list = tf.convert_to_tensor(weight_vector)\n",
    "tensor_from_list = K.cast(tensor_from_list, \"float32\")\n",
    "\n",
    "print(\"Weight Vector\")\n",
    "print(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func1(y_true, y_pred):\n",
    "    # tile sprite loss\n",
    "    r_loss=K.mean(K.square(y_true - y_pred), axis=[1,2,3])\n",
    "    loss  =  r_loss\n",
    "    return loss\n",
    "\n",
    "    \n",
    "def loss_func4(y_true,y_pred):\n",
    "    # multilabel text weighted bce\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\n",
    "    weighted_array=bce_array*tensor_from_list\n",
    "    bce_sum=K.sum(weighted_array,axis=1)\n",
    "    loss=bce_sum/13.0\n",
    "    return loss\n",
    "\n",
    "    \n",
    "losses ={'image_output_layer':loss_func1,\n",
    "          'text_output_layer':loss_func4,\n",
    "}\n",
    "\n",
    "\n",
    "#tweak loss weights\n",
    "lossWeights={'image_output_layer':0.1,\n",
    "          'text_output_layer':0.9  \n",
    "        }\n",
    "\n",
    "\n",
    "def check_nonzero(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric\n",
    "    Returns sum of all embeddings\n",
    "    \"\"\"\n",
    "    return(K.sum(K.cast(y_pred > 0.4, 'int32')))\n",
    "\n",
    "accuracy={\n",
    "    'image_output_layer':loss_func1,\n",
    "    'text_output_layer': check_nonzero\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "ae_sep_output.compile(\n",
    "    optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics=accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-chassis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with loss func 2 that is by using in built cross-entropy loss\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_text_output_layer_loss\", mode=\"min\", verbose=1, patience=2\n",
    ")\n",
    "\n",
    "ae_history = ae_sep_output.fit(\n",
    "    [train_image_batch, train_text_batch],\n",
    "    [output_image_batch, output_text_batch],\n",
    "    epochs=10,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-representative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build the inference model\n",
    "\n",
    "decoder_input = Input(shape=(256,))\n",
    "\n",
    "d_dense = ae_sep_output.get_layer(\"image_dense\")(decoder_input)\n",
    "d_reshape = ae_sep_output.get_layer(\"image_reshape\")(d_dense)\n",
    "d_conv1 = ae_sep_output.get_layer(\"idecode_conv1\")(d_reshape)\n",
    "d_norm1 = ae_sep_output.get_layer(\"idecode_norm1\")(d_conv1)\n",
    "d_relu1 = ae_sep_output.get_layer(\"idecode_relu1\")(d_norm1)\n",
    "d_conv2 = ae_sep_output.get_layer(\"idecode_conv2\")(d_relu1)\n",
    "d_norm2 = ae_sep_output.get_layer(\"idecode_norm2\")(d_conv2)\n",
    "d_relu2 = ae_sep_output.get_layer(\"idecode_relu2\")(d_norm2)\n",
    "d_image_output = ae_sep_output.get_layer(\"image_output_layer\")(d_relu2)\n",
    "\n",
    "t_dense = ae_sep_output.get_layer(\"tdecode_dense1\")(decoder_input)\n",
    "t_reshape = ae_sep_output.get_layer(\"text_reshape\")(t_dense)\n",
    "t_dense2 = ae_sep_output.get_layer(\"tdecode_dense2\")(t_reshape)\n",
    "d_text_output = ae_sep_output.get_layer(\"text_output_layer\")(t_dense2)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model weights, multilabel binarizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(\"model_tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "## saving the entire architecture model\n",
    "model_json = ae_sep_output.to_json()\n",
    "with open(\"autoencoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "ae_sep_output.save_weights(\"autoencoder_model.h5\")\n",
    "print(\"Saved Entire Model to disk\")\n",
    "\n",
    "## saving the encoder part\n",
    "model_json = encoding_model.to_json()\n",
    "with open(\"encoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "encoding_model.save_weights(\"encoder_model.h5\")\n",
    "print(\"Saved Encoder Model to disk\")\n",
    "## saving the encoder part\n",
    "\n",
    "model_json = decoder_model.to_json()\n",
    "with open(\"decoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "decoder_model.save_weights(\"decoder_model.h5\")\n",
    "print(\"Saved Decoder Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_divide(num, den):\n",
    "    count = 0\n",
    "    result = {}\n",
    "    for idx in range(len(num)):\n",
    "        if num[idx] == den[idx] == 0:\n",
    "            continue\n",
    "        elif num[idx] != 0 and den[idx] != 0:\n",
    "            result[idx] = num[idx] / den[idx]\n",
    "            count += 1\n",
    "        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\n",
    "            count += 1\n",
    "            result[idx] = 0.0\n",
    "    return result, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_embeddings",
   "language": "python",
   "name": "tile_embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
