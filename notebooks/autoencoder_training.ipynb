{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atomic-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
<<<<<<< HEAD
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nfrom sklearn.utils import shuffle\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom notebook_utils import initialize_environment\\n\\ninitialize_environment()\\n\\nfrom utils.evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom utils.data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
=======
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nfrom sklearn.utils import shuffle\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom notebook_utils import initialize_environment\\ninitialize_environment()\\n\\nfrom utils.evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom utils.data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
       "                var nbb_formatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nfrom sklearn.utils import shuffle\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom notebook_utils import initialize_environment\\n\\ninitialize_environment()\\n\\nfrom utils.evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom utils.evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom utils.data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "from notebook_utils import initialize_environment\n",
    "\n",
    "initialize_environment()\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from utils.data_loading.load_data import get_tile_data\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-speech",
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games detected in the parent folder ['lode_runner', 'kid_icarus', 'megaman', 'smb', 'loz']\n",
      "Current Game lode_runner\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/lode_runner\n",
      "Current Game kid_icarus\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/kid_icarus\n",
      "Current Game megaman\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/megaman\n",
      "Current Game smb\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/smb\n",
      "Current Game loz\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/loz\n",
      "\n",
      "The size of total data is (25394, 5)\n",
      "\n",
      "The size of the train data is  (22854, 5)\n",
      "The size of the test data is  (2540, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"##loading train and testing data\\n\\ndata_directory = \\\"../data/context_data/\\\"\\njson_directory = \\\"../data/json_files_trimmed_features/\\\"\\ndata = get_tile_data(data_directory, json_directory)\\nprint(\\\"\\\\nThe size of total data is\\\", data.shape)\\ndata = shuffle(data)\\n\\n# split into train-test\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\\n\\nprint(\\\"\\\\nThe size of the train data is \\\", train_data.shape)\\nprint(\\\"The size of the test data is \\\", test_data.shape)\";\n",
       "                var nbb_formatted_code = \"##loading train and testing data\\n\\ndata_directory = \\\"../data/context_data/\\\"\\njson_directory = \\\"../data/json_files_trimmed_features/\\\"\\ndata = get_tile_data(data_directory, json_directory)\\nprint(\\\"\\\\nThe size of total data is\\\", data.shape)\\ndata = shuffle(data)\\n\\n# split into train-test\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\\n\\nprint(\\\"\\\\nThe size of the train data is \\\", train_data.shape)\\nprint(\\\"The size of the test data is \\\", test_data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "##loading train and testing data\n",
    "\n",
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "data = get_tile_data(data_directory, json_directory)\n",
    "print(\"\\nThe size of total data is\", data.shape)\n",
    "data = shuffle(data)\n",
    "\n",
    "# split into train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\n",
    "\n",
    "print(\"\\nThe size of the train data is \", train_data.shape)\n",
    "print(\"The size of the test data is \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "taken-vaccine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25394, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"data.shape\";\n",
       "                var nbb_formatted_code = \"data.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incomplete-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature Dictionary..\n",
      "The feature dictionary has size 13\n",
      "Printing Feature classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['block', 'breakable', 'climbable', 'collectable', 'element',\n",
       "       'empty', 'hazard', 'moving', 'openable', 'passable', 'pipe',\n",
       "       'solid', 'wall'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Feature Dictionary\\nprint(\\\"Building feature Dictionary..\\\")\\nmlb = MultiLabelBinarizer()\\ncombined_features = np.concatenate(\\n    [train_data[\\\"features\\\"], test_data[\\\"features\\\"]], axis=0\\n)\\nmlb_model = mlb.fit(combined_features)\\ntotal_features = len(mlb_model.classes_)\\nprint(\\\"The feature dictionary has size\\\", total_features)\\nprint(\\\"Printing Feature classes\\\")\\ndisplay(mlb_model.classes_)\";\n",
       "                var nbb_formatted_code = \"# Feature Dictionary\\nprint(\\\"Building feature Dictionary..\\\")\\nmlb = MultiLabelBinarizer()\\ncombined_features = np.concatenate(\\n    [train_data[\\\"features\\\"], test_data[\\\"features\\\"]], axis=0\\n)\\nmlb_model = mlb.fit(combined_features)\\ntotal_features = len(mlb_model.classes_)\\nprint(\\\"The feature dictionary has size\\\", total_features)\\nprint(\\\"Printing Feature classes\\\")\\ndisplay(mlb_model.classes_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "incomplete-meter",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "# Feature Dictionary\n",
    "print(\"Building feature Dictionary..\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "combined_features = np.concatenate(\n",
    "    [train_data[\"features\"], test_data[\"features\"]], axis=0\n",
    ")\n",
    "mlb_model = mlb.fit(combined_features)\n",
    "total_features = len(mlb_model.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "print(\"Printing Feature classes\")\n",
    "display(mlb_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "toxic-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Batches\n",
      "Training Data Ready\n",
      "Train Image batch shape (22854, 48, 48, 3)\n",
      "Train Text batch shape (22854, 13)\n",
      "Output Image batch shape (22854, 16, 16, 3)\n",
      "Output Text batch shape (22854, 13)\n",
      "Building Testing Batches\n",
      "\n",
      "\n",
      "Testing Data Ready\n",
      "Train Image batch shape (2540, 48, 48, 3)\n",
      "Train Text batch shape (2540, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Build Input Output Training Batches\\nprint(\\\"Building Training Batches\\\")\\n\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntrain_image_batch = []\\nfor train_path in train_data[\\\"image_path\\\"]:\\n    tile = image.load_img(train_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    train_image_batch.append(tile_sprite)\\ntrain_image_batch = np.array(train_image_batch)\\ntrain_text_batch = []\\nfor i in range(len(train_data[\\\"features\\\"])):\\n    text_ = mlb.transform(train_data[\\\"features\\\"][i : i + 1])\\n    train_text_batch.append(text_)\\ntrain_text_batch = np.array(train_text_batch).reshape(\\n    train_data.shape[0], total_features\\n)\\n\\noutput_image_batch = []\\nfor i in range(len(train_image_batch)):\\n    current_image = train_image_batch[i]\\n    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    output_image_batch.append(current_image_centre)\\noutput_image_batch = np.array(output_image_batch)\\noutput_text_batch = []\\nfor i in range(len(train_text_batch)):\\n    current_text = train_text_batch[i]\\n    output_text_batch.append(current_text)\\noutput_text_batch = np.array(output_text_batch)\\nprint(\\\"Training Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", train_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", train_text_batch.shape)\\nprint(\\\"Output Image batch shape\\\", output_image_batch.shape)\\nprint(\\\"Output Text batch shape\\\", output_text_batch.shape)\\n\\n\\n# Build Input Output Test Batches\\nprint(\\\"Building Testing Batches\\\")\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntest_image_batch = []\\nfor test_path in test_data[\\\"image_path\\\"]:\\n    tile = image.load_img(test_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    test_image_batch.append(tile_sprite)\\ntest_image_batch = np.array(test_image_batch)\\ntest_text_batch = []\\nfor i in range(len(test_data[\\\"features\\\"])):\\n    text_ = mlb.transform(test_data[\\\"features\\\"][i : i + 1])\\n    test_text_batch.append(text_)\\ntest_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\\nprint(\\\"\\\\n\\\\nTesting Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", test_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", test_text_batch.shape)\";\n",
       "                var nbb_formatted_code = \"# Build Input Output Training Batches\\nprint(\\\"Building Training Batches\\\")\\n\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntrain_image_batch = []\\nfor train_path in train_data[\\\"image_path\\\"]:\\n    tile = image.load_img(train_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    train_image_batch.append(tile_sprite)\\ntrain_image_batch = np.array(train_image_batch)\\ntrain_text_batch = []\\nfor i in range(len(train_data[\\\"features\\\"])):\\n    text_ = mlb.transform(train_data[\\\"features\\\"][i : i + 1])\\n    train_text_batch.append(text_)\\ntrain_text_batch = np.array(train_text_batch).reshape(\\n    train_data.shape[0], total_features\\n)\\n\\noutput_image_batch = []\\nfor i in range(len(train_image_batch)):\\n    current_image = train_image_batch[i]\\n    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    output_image_batch.append(current_image_centre)\\noutput_image_batch = np.array(output_image_batch)\\noutput_text_batch = []\\nfor i in range(len(train_text_batch)):\\n    current_text = train_text_batch[i]\\n    output_text_batch.append(current_text)\\noutput_text_batch = np.array(output_text_batch)\\nprint(\\\"Training Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", train_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", train_text_batch.shape)\\nprint(\\\"Output Image batch shape\\\", output_image_batch.shape)\\nprint(\\\"Output Text batch shape\\\", output_text_batch.shape)\\n\\n\\n# Build Input Output Test Batches\\nprint(\\\"Building Testing Batches\\\")\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntest_image_batch = []\\nfor test_path in test_data[\\\"image_path\\\"]:\\n    tile = image.load_img(test_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    test_image_batch.append(tile_sprite)\\ntest_image_batch = np.array(test_image_batch)\\ntest_text_batch = []\\nfor i in range(len(test_data[\\\"features\\\"])):\\n    text_ = mlb.transform(test_data[\\\"features\\\"][i : i + 1])\\n    test_text_batch.append(text_)\\ntest_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\\nprint(\\\"\\\\n\\\\nTesting Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", test_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", test_text_batch.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "toxic-seventh",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "# Build Input Output Training Batches\n",
    "print(\"Building Training Batches\")\n",
    "\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "train_image_batch = []\n",
    "for train_path in train_data[\"image_path\"]:\n",
    "    tile = image.load_img(train_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    train_image_batch.append(tile_sprite)\n",
    "train_image_batch = np.array(train_image_batch)\n",
    "train_text_batch = []\n",
    "for i in range(len(train_data[\"features\"])):\n",
    "    text_ = mlb.transform(train_data[\"features\"][i : i + 1])\n",
    "    train_text_batch.append(text_)\n",
    "train_text_batch = np.array(train_text_batch).reshape(\n",
    "    train_data.shape[0], total_features\n",
    ")\n",
    "\n",
    "output_image_batch = []\n",
    "for i in range(len(train_image_batch)):\n",
    "    current_image = train_image_batch[i]\n",
    "    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    output_image_batch.append(current_image_centre)\n",
    "output_image_batch = np.array(output_image_batch)\n",
    "output_text_batch = []\n",
    "for i in range(len(train_text_batch)):\n",
    "    current_text = train_text_batch[i]\n",
    "    output_text_batch.append(current_text)\n",
    "output_text_batch = np.array(output_text_batch)\n",
    "print(\"Training Data Ready\")\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "\n",
    "# Build Input Output Test Batches\n",
    "print(\"Building Testing Batches\")\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "test_image_batch = []\n",
    "for test_path in test_data[\"image_path\"]:\n",
    "    tile = image.load_img(test_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    test_image_batch.append(tile_sprite)\n",
    "test_image_batch = np.array(test_image_batch)\n",
    "test_text_batch = []\n",
    "for i in range(len(test_data[\"features\"])):\n",
    "    text_ = mlb.transform(test_data[\"features\"][i : i + 1])\n",
    "    test_text_batch.append(text_)\n",
    "test_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\n",
    "print(\"\\n\\nTesting Data Ready\")\n",
    "print(\"Train Image batch shape\", test_image_batch.shape)\n",
    "print(\"Train Text batch shape\", test_text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "demographic-hobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"import pickle\\n\\n# saving\\nwith open(\\\"train_image_batch.pickle\\\", \\\"wb\\\") as handle:\\n    pickle.dump(train_image_batch, handle, protocol=pickle.HIGHEST_PROTOCOL)\";\n",
       "                var nbb_formatted_code = \"import pickle\\n\\n# saving\\nwith open(\\\"train_image_batch.pickle\\\", \\\"wb\\\") as handle:\\n    pickle.dump(train_image_batch, handle, protocol=pickle.HIGHEST_PROTOCOL)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(\"train_image_batch.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(train_image_batch, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "referenced-boating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"with open(\\\"train_image_batch.pickle\\\", \\\"rb\\\") as handle:\\n    train_image_batch_2 = pickle.load(handle)\";\n",
       "                var nbb_formatted_code = \"with open(\\\"train_image_batch.pickle\\\", \\\"rb\\\") as handle:\\n    train_image_batch_2 = pickle.load(handle)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"train_image_batch.pickle\", \"rb\") as handle:\n",
    "    train_image_batch_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extreme-stereo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22854, 48, 48, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"train_image_batch_2.shape\";\n",
       "                var nbb_formatted_code = \"train_image_batch_2.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image_batch_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earned-keyboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# model definition\\n\\nlatent_dim = 128\\nbatch_size = 1\\n\\n# image encoder\\nimage_encoder_input = Input(shape=(48, 48, 3), name=\\\"image_input\\\")\\n\\nimage_encoder_conv_layer1 = Conv2D(\\n    32, strides=3, kernel_size=(3, 3), name=\\\"iencode_conv1\\\"\\n)(image_encoder_input)\\nimage_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\\nimage_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\\n\\nimage_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv2\\\")(\\n    image_encoder_actv_layer1\\n)\\nimage_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\\nimage_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\\n\\nimage_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv3\\\")(\\n    image_encoder_actv_layer2\\n)\\nimage_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\\nimage_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\\n\\nimage_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\\nimage_flatten = Flatten(name=\\\"image_flatten_layer\\\")(image_encoder_actv_layer3)\\n\\n\\n# text encoder\\ntext_encoder_input = Input(shape=(13,))\\n\\ntext_encoder_dense_layer1 = Dense(32, activation=\\\"tanh\\\", name=\\\"tencode_dense1\\\")(\\n    text_encoder_input\\n)\\ntext_encoder_dense_layer2 = Dense(16, activation=\\\"tanh\\\", name=\\\"tencode_dense2\\\")(\\n    text_encoder_dense_layer1\\n)\\ntext_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\\n\\n# image-text concatenation\\nimage_text_concat = Concatenate(name=\\\"image_text_concatenation\\\")(\\n    [image_flatten, text_encoder_dense_layer2]\\n)\\n\\nimage_text_concat = Dense(256, activation=\\\"tanh\\\", name=\\\"embedding_dense_1\\\")(\\n    image_text_concat\\n)\\n\\n\\n##\\nencoding_model = Model(\\n    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\\n)\\n\\n# decoder for image\\n\\n# decoder_input=Input(shape=(512,))\\n\\nimage_y = Dense(units=np.prod(image_shape_before_flatten), name=\\\"image_dense\\\")(\\n    image_text_concat\\n)\\nimage_y = Reshape(target_shape=image_shape_before_flatten, name=\\\"image_reshape\\\")(\\n    image_y\\n)\\n\\nimage_decoder_convt_layer1 = Conv2DTranspose(\\n    16, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv1\\\"\\n)(image_y)\\nimage_decoder_norm_layer1 = BatchNormalization(name=\\\"idecode_norm1\\\")(\\n    image_decoder_convt_layer1\\n)\\nimage_decoder_actv_layer1 = ReLU(name=\\\"idecode_relu1\\\")(image_decoder_norm_layer1)\\n\\n\\nimage_decoder_convt_layer2 = Conv2DTranspose(\\n    32, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv2\\\"\\n)(image_decoder_actv_layer1)\\nimage_decoder_norm_layer2 = BatchNormalization(name=\\\"idecode_norm2\\\")(\\n    image_decoder_convt_layer2\\n)\\nimage_decoder_actv_layer2 = ReLU(name=\\\"idecode_relu2\\\")(image_decoder_norm_layer2)\\n\\nimage_decoder_output = Conv2DTranspose(\\n    3, (3, 3), padding=\\\"same\\\", name=\\\"image_output_layer\\\"\\n)(image_decoder_actv_layer2)\\n\\n\\n# decoder for text\\n\\ntext_decoder_dense_layer1 = Dense(16, activation=\\\"tanh\\\", name=\\\"tdecode_dense1\\\")(\\n    image_text_concat\\n)\\ntext_reshape = Reshape(target_shape=text_shape_before_concat, name=\\\"text_reshape\\\")(\\n    text_decoder_dense_layer1\\n)\\ntext_decoder_dense_layer2 = Dense(32, activation=\\\"tanh\\\", name=\\\"tdecode_dense2\\\")(\\n    text_reshape\\n)\\n\\ntext_decoder_output = Dense(13, activation=\\\"sigmoid\\\", name=\\\"text_output_layer\\\")(\\n    text_decoder_dense_layer2\\n)\\n\\n\\n# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\\n\\n\\nae_sep_output = Model(\\n    [image_encoder_input, text_encoder_input],\\n    [image_decoder_output, text_decoder_output],\\n)\";\n",
       "                var nbb_formatted_code = \"# model definition\\n\\nlatent_dim = 128\\nbatch_size = 1\\n\\n# image encoder\\nimage_encoder_input = Input(shape=(48, 48, 3), name=\\\"image_input\\\")\\n\\nimage_encoder_conv_layer1 = Conv2D(\\n    32, strides=3, kernel_size=(3, 3), name=\\\"iencode_conv1\\\"\\n)(image_encoder_input)\\nimage_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\\nimage_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\\n\\nimage_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv2\\\")(\\n    image_encoder_actv_layer1\\n)\\nimage_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\\nimage_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\\n\\nimage_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv3\\\")(\\n    image_encoder_actv_layer2\\n)\\nimage_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\\nimage_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\\n\\nimage_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\\nimage_flatten = Flatten(name=\\\"image_flatten_layer\\\")(image_encoder_actv_layer3)\\n\\n\\n# text encoder\\ntext_encoder_input = Input(shape=(13,))\\n\\ntext_encoder_dense_layer1 = Dense(32, activation=\\\"tanh\\\", name=\\\"tencode_dense1\\\")(\\n    text_encoder_input\\n)\\ntext_encoder_dense_layer2 = Dense(16, activation=\\\"tanh\\\", name=\\\"tencode_dense2\\\")(\\n    text_encoder_dense_layer1\\n)\\ntext_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\\n\\n# image-text concatenation\\nimage_text_concat = Concatenate(name=\\\"image_text_concatenation\\\")(\\n    [image_flatten, text_encoder_dense_layer2]\\n)\\n\\nimage_text_concat = Dense(256, activation=\\\"tanh\\\", name=\\\"embedding_dense_1\\\")(\\n    image_text_concat\\n)\\n\\n\\n##\\nencoding_model = Model(\\n    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\\n)\\n\\n# decoder for image\\n\\n# decoder_input=Input(shape=(512,))\\n\\nimage_y = Dense(units=np.prod(image_shape_before_flatten), name=\\\"image_dense\\\")(\\n    image_text_concat\\n)\\nimage_y = Reshape(target_shape=image_shape_before_flatten, name=\\\"image_reshape\\\")(\\n    image_y\\n)\\n\\nimage_decoder_convt_layer1 = Conv2DTranspose(\\n    16, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv1\\\"\\n)(image_y)\\nimage_decoder_norm_layer1 = BatchNormalization(name=\\\"idecode_norm1\\\")(\\n    image_decoder_convt_layer1\\n)\\nimage_decoder_actv_layer1 = ReLU(name=\\\"idecode_relu1\\\")(image_decoder_norm_layer1)\\n\\n\\nimage_decoder_convt_layer2 = Conv2DTranspose(\\n    32, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv2\\\"\\n)(image_decoder_actv_layer1)\\nimage_decoder_norm_layer2 = BatchNormalization(name=\\\"idecode_norm2\\\")(\\n    image_decoder_convt_layer2\\n)\\nimage_decoder_actv_layer2 = ReLU(name=\\\"idecode_relu2\\\")(image_decoder_norm_layer2)\\n\\nimage_decoder_output = Conv2DTranspose(\\n    3, (3, 3), padding=\\\"same\\\", name=\\\"image_output_layer\\\"\\n)(image_decoder_actv_layer2)\\n\\n\\n# decoder for text\\n\\ntext_decoder_dense_layer1 = Dense(16, activation=\\\"tanh\\\", name=\\\"tdecode_dense1\\\")(\\n    image_text_concat\\n)\\ntext_reshape = Reshape(target_shape=text_shape_before_concat, name=\\\"text_reshape\\\")(\\n    text_decoder_dense_layer1\\n)\\ntext_decoder_dense_layer2 = Dense(32, activation=\\\"tanh\\\", name=\\\"tdecode_dense2\\\")(\\n    text_reshape\\n)\\n\\ntext_decoder_output = Dense(13, activation=\\\"sigmoid\\\", name=\\\"text_output_layer\\\")(\\n    text_decoder_dense_layer2\\n)\\n\\n\\n# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\\n\\n\\nae_sep_output = Model(\\n    [image_encoder_input, text_encoder_input],\\n    [image_decoder_output, text_decoder_output],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "earned-keyboard",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "# model definition\n",
    "\n",
    "latent_dim = 128\n",
    "batch_size = 1\n",
    "\n",
    "# image encoder\n",
    "image_encoder_input = Input(shape=(48, 48, 3), name=\"image_input\")\n",
    "\n",
    "image_encoder_conv_layer1 = Conv2D(\n",
    "    32, strides=3, kernel_size=(3, 3), name=\"iencode_conv1\"\n",
    ")(image_encoder_input)\n",
    "image_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\n",
    "image_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\n",
    "\n",
    "image_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\"same\", name=\"iencode_conv2\")(\n",
    "    image_encoder_actv_layer1\n",
    ")\n",
    "image_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\n",
    "image_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\n",
    "\n",
    "image_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\"same\", name=\"iencode_conv3\")(\n",
    "    image_encoder_actv_layer2\n",
    ")\n",
    "image_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\n",
    "image_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\n",
    "\n",
    "image_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\n",
    "image_flatten = Flatten(name=\"image_flatten_layer\")(image_encoder_actv_layer3)\n",
    "\n",
    "\n",
    "# text encoder\n",
    "text_encoder_input = Input(shape=(13,))\n",
    "\n",
    "text_encoder_dense_layer1 = Dense(32, activation=\"tanh\", name=\"tencode_dense1\")(\n",
    "    text_encoder_input\n",
    ")\n",
    "text_encoder_dense_layer2 = Dense(16, activation=\"tanh\", name=\"tencode_dense2\")(\n",
    "    text_encoder_dense_layer1\n",
    ")\n",
    "text_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\n",
    "\n",
    "# image-text concatenation\n",
    "image_text_concat = Concatenate(name=\"image_text_concatenation\")(\n",
    "    [image_flatten, text_encoder_dense_layer2]\n",
    ")\n",
    "\n",
    "image_text_concat = Dense(256, activation=\"tanh\", name=\"embedding_dense_1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "\n",
    "\n",
    "##\n",
    "encoding_model = Model(\n",
    "    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\n",
    ")\n",
    "\n",
    "# decoder for image\n",
    "\n",
    "# decoder_input=Input(shape=(512,))\n",
    "\n",
    "image_y = Dense(units=np.prod(image_shape_before_flatten), name=\"image_dense\")(\n",
    "    image_text_concat\n",
    ")\n",
    "image_y = Reshape(target_shape=image_shape_before_flatten, name=\"image_reshape\")(\n",
    "    image_y\n",
    ")\n",
    "\n",
    "image_decoder_convt_layer1 = Conv2DTranspose(\n",
    "    16, (3, 3), padding=\"same\", name=\"idecode_conv1\"\n",
    ")(image_y)\n",
    "image_decoder_norm_layer1 = BatchNormalization(name=\"idecode_norm1\")(\n",
    "    image_decoder_convt_layer1\n",
    ")\n",
    "image_decoder_actv_layer1 = ReLU(name=\"idecode_relu1\")(image_decoder_norm_layer1)\n",
    "\n",
    "\n",
    "image_decoder_convt_layer2 = Conv2DTranspose(\n",
    "    32, (3, 3), padding=\"same\", name=\"idecode_conv2\"\n",
    ")(image_decoder_actv_layer1)\n",
    "image_decoder_norm_layer2 = BatchNormalization(name=\"idecode_norm2\")(\n",
    "    image_decoder_convt_layer2\n",
    ")\n",
    "image_decoder_actv_layer2 = ReLU(name=\"idecode_relu2\")(image_decoder_norm_layer2)\n",
    "\n",
    "image_decoder_output = Conv2DTranspose(\n",
    "    3, (3, 3), padding=\"same\", name=\"image_output_layer\"\n",
    ")(image_decoder_actv_layer2)\n",
    "\n",
    "\n",
    "# decoder for text\n",
    "\n",
    "text_decoder_dense_layer1 = Dense(16, activation=\"tanh\", name=\"tdecode_dense1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "text_reshape = Reshape(target_shape=text_shape_before_concat, name=\"text_reshape\")(\n",
    "    text_decoder_dense_layer1\n",
    ")\n",
    "text_decoder_dense_layer2 = Dense(32, activation=\"tanh\", name=\"tdecode_dense2\")(\n",
    "    text_reshape\n",
    ")\n",
    "\n",
    "text_decoder_output = Dense(13, activation=\"sigmoid\", name=\"text_output_layer\")(\n",
    "    text_decoder_dense_layer2\n",
    ")\n",
    "\n",
    "\n",
    "# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\n",
    "\n",
    "\n",
    "ae_sep_output = Model(\n",
    "    [image_encoder_input, text_encoder_input],\n",
    "    [image_decoder_output, text_decoder_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "id": "recreational-newsletter",
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv1 (Conv2D)          (None, 16, 16, 32)   896         image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 32)   128         iencode_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 16, 16, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv2 (Conv2D)          (None, 16, 16, 32)   9248        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 32)   128         iencode_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 16, 16, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv3 (Conv2D)          (None, 16, 16, 16)   4624        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16)   64          iencode_conv3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 16, 16, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tencode_dense1 (Dense)          (None, 32)           448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_flatten_layer (Flatten)   (None, 4096)         0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tencode_dense2 (Dense)          (None, 16)           528         tencode_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "image_text_concatenation (Conca (None, 4112)         0           image_flatten_layer[0][0]        \n",
      "                                                                 tencode_dense2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_dense_1 (Dense)       (None, 256)          1052928     image_text_concatenation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "image_dense (Dense)             (None, 4096)         1052672     embedding_dense_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "image_reshape (Reshape)         (None, 16, 16, 16)   0           image_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv1 (Conv2DTranspose) (None, 16, 16, 16)   2320        image_reshape[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm1 (BatchNormalizati (None, 16, 16, 16)   64          idecode_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu1 (ReLU)            (None, 16, 16, 16)   0           idecode_norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv2 (Conv2DTranspose) (None, 16, 16, 32)   4640        idecode_relu1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense1 (Dense)          (None, 16)           4112        embedding_dense_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm2 (BatchNormalizati (None, 16, 16, 32)   128         idecode_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_reshape (Reshape)          (None, 16)           0           tdecode_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu2 (ReLU)            (None, 16, 16, 32)   0           idecode_norm2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense2 (Dense)          (None, 32)           544         text_reshape[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "image_output_layer (Conv2DTrans (None, 16, 16, 3)    867         idecode_relu2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_output_layer (Dense)       (None, 13)           429         tdecode_dense2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,134,768\n",
      "Trainable params: 2,134,512\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"ae_sep_output.get_layer(\\\"tdecode_dense1\\\")\\nprint(ae_sep_output.summary())\";\n",
       "                var nbb_formatted_code = \"ae_sep_output.get_layer(\\\"tdecode_dense1\\\")\\nprint(ae_sep_output.summary())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "ae_sep_output.get_layer(\"tdecode_dense1\")\n",
    "print(ae_sep_output.summary())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "several-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mumu/.local/share/virtualenvs/tile_embeddings-p9MPY-Te/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Printing the TF-IDF for the labels\n",
      "\n",
      " {'block': 5.099388985683419, 'breakable': 2.5897253711701422, 'climbable': 2.772819427036889, 'collectable': 4.082286325884857, 'element': 5.611975173284442, 'empty': 2.0895092401157163, 'hazard': 4.804477174215322, 'moving': 6.216643625160808, 'openable': 6.548288821033705, 'passable': 1.6013634276804867, 'pipe': 6.472576999298009, 'solid': 1.8296896337431408, 'wall': 5.268604194972072}\n",
      "\n",
      "Printing the weight normalised\n",
      "\n",
      "\n",
      "{'block': 0.09273749569910669, 'breakable': 0.047096749462538154, 'climbable': 0.05042649823560588, 'collectable': 0.0742404652110554, 'element': 0.102059388871314, 'empty': 0.03799981815713655, 'hazard': 0.08737422905590256, 'moving': 0.11305589023896849, 'openable': 0.11908719026574421, 'passable': 0.029122397684145894, 'pipe': 0.11771029496273867, 'solid': 0.033274738408137744, 'wall': 0.09581484374760564}\n",
      "Weight Vector\n",
      "[5099.3889856834185, 2589.7253711701424, 2772.819427036889, 4082.2863258848565, 5611.9751732844425, 2089.5092401157162, 4804.477174215322, 6216.643625160808, 6548.288821033705, 1601.3634276804867, 6472.576999298009, 1829.6896337431408, 5268.604194972072]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\nfrom ast import literal_eval\\nimport tensorflow as tf\\n\\nvectorizer = TfidfVectorizer(stop_words=None)\\ntrain_data_copy = train_data\\ntrain_data_copy[\\\"features\\\"] = train_data_copy.features.apply(lambda x: str(x))\\nvectors = vectorizer.fit_transform(train_data_copy[\\\"features\\\"])\\n\\nidf = vectorizer.idf_\\n\\n# build the weight dictionary\\nnew_dict = {}\\nfor c in mlb.classes_:\\n    if c in vectorizer.vocabulary_.keys():\\n        new_dict[c] = idf[vectorizer.vocabulary_[c]]\\n    else:\\n        new_dict[c] = np.max(idf)\\nprint(\\\"\\\\n Printing the TF-IDF for the labels\\\\n\\\\n\\\", new_dict)\\n\\n\\nweight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\\n\\nprint(\\\"\\\\nPrinting the weight normalised\\\\n\\\\n\\\")\\nprint(weight_freq)\\n\\nweight_vector = [v * 1000 for v in new_dict.values()]\\n\\ntensor_from_list = tf.convert_to_tensor(weight_vector)\\ntensor_from_list = K.cast(tensor_from_list, \\\"float32\\\")\\n\\nprint(\\\"Weight Vector\\\")\\nprint(weight_vector)\";\n",
       "                var nbb_formatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\nfrom ast import literal_eval\\nimport tensorflow as tf\\n\\nvectorizer = TfidfVectorizer(stop_words=None)\\ntrain_data_copy = train_data\\ntrain_data_copy[\\\"features\\\"] = train_data_copy.features.apply(lambda x: str(x))\\nvectors = vectorizer.fit_transform(train_data_copy[\\\"features\\\"])\\n\\nidf = vectorizer.idf_\\n\\n# build the weight dictionary\\nnew_dict = {}\\nfor c in mlb.classes_:\\n    if c in vectorizer.vocabulary_.keys():\\n        new_dict[c] = idf[vectorizer.vocabulary_[c]]\\n    else:\\n        new_dict[c] = np.max(idf)\\nprint(\\\"\\\\n Printing the TF-IDF for the labels\\\\n\\\\n\\\", new_dict)\\n\\n\\nweight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\\n\\nprint(\\\"\\\\nPrinting the weight normalised\\\\n\\\\n\\\")\\nprint(weight_freq)\\n\\nweight_vector = [v * 1000 for v in new_dict.values()]\\n\\ntensor_from_list = tf.convert_to_tensor(weight_vector)\\ntensor_from_list = K.cast(tensor_from_list, \\\"float32\\\")\\n\\nprint(\\\"Weight Vector\\\")\\nprint(weight_vector)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "several-proposal",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "import tensorflow as tf\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=None)\n",
    "train_data_copy = train_data\n",
    "train_data_copy[\"features\"] = train_data_copy.features.apply(lambda x: str(x))\n",
    "vectors = vectorizer.fit_transform(train_data_copy[\"features\"])\n",
    "\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "# build the weight dictionary\n",
    "new_dict = {}\n",
    "for c in mlb.classes_:\n",
    "    if c in vectorizer.vocabulary_.keys():\n",
    "        new_dict[c] = idf[vectorizer.vocabulary_[c]]\n",
    "    else:\n",
    "        new_dict[c] = np.max(idf)\n",
    "print(\"\\n Printing the TF-IDF for the labels\\n\\n\", new_dict)\n",
    "\n",
    "\n",
    "weight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\n",
    "\n",
    "print(\"\\nPrinting the weight normalised\\n\\n\")\n",
    "print(weight_freq)\n",
    "\n",
    "weight_vector = [v * 1000 for v in new_dict.values()]\n",
    "\n",
    "tensor_from_list = tf.convert_to_tensor(weight_vector)\n",
    "tensor_from_list = K.cast(tensor_from_list, \"float32\")\n",
    "\n",
    "print(\"Weight Vector\")\n",
    "print(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "increased-camera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def loss_func1(y_true, y_pred):\\n    # tile sprite loss\\n    r_loss=K.mean(K.square(y_true - y_pred), axis=[1,2,3])\\n    loss  =  r_loss\\n    return loss\\n\\n    \\ndef loss_func4(y_true,y_pred):\\n    # multilabel text weighted bce\\n    y_true = K.cast(y_true, 'float32')\\n    y_pred = K.cast(y_pred, 'float32')\\n    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\\n    weighted_array=bce_array*tensor_from_list\\n    bce_sum=K.sum(weighted_array,axis=1)\\n    loss=bce_sum/13.0\\n    return loss\\n\\n    \\nlosses ={'image_output_layer':loss_func1,\\n          'text_output_layer':loss_func4,\\n}\\n\\n\\n#tweak loss weights\\nlossWeights={'image_output_layer':0.1,\\n          'text_output_layer':0.9  \\n        }\\n\\n\\ndef check_nonzero(y_true,y_pred):\\n    \\\"\\\"\\\"\\n    Custom metric\\n    Returns sum of all embeddings\\n    \\\"\\\"\\\"\\n    return(K.sum(K.cast(y_pred > 0.4, 'int32')))\\n\\naccuracy={\\n    'image_output_layer':loss_func1,\\n    'text_output_layer': check_nonzero\\n}\";\n",
       "                var nbb_formatted_code = \"def loss_func1(y_true, y_pred):\\n    # tile sprite loss\\n    r_loss = K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])\\n    loss = r_loss\\n    return loss\\n\\n\\ndef loss_func4(y_true, y_pred):\\n    # multilabel text weighted bce\\n    y_true = K.cast(y_true, \\\"float32\\\")\\n    y_pred = K.cast(y_pred, \\\"float32\\\")\\n    bce_array = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\\n    weighted_array = bce_array * tensor_from_list\\n    bce_sum = K.sum(weighted_array, axis=1)\\n    loss = bce_sum / 13.0\\n    return loss\\n\\n\\nlosses = {\\n    \\\"image_output_layer\\\": loss_func1,\\n    \\\"text_output_layer\\\": loss_func4,\\n}\\n\\n\\n# tweak loss weights\\nlossWeights = {\\\"image_output_layer\\\": 0.1, \\\"text_output_layer\\\": 0.9}\\n\\n\\ndef check_nonzero(y_true, y_pred):\\n    \\\"\\\"\\\"\\n    Custom metric\\n    Returns sum of all embeddings\\n    \\\"\\\"\\\"\\n    return K.sum(K.cast(y_pred > 0.4, \\\"int32\\\"))\\n\\n\\naccuracy = {\\\"image_output_layer\\\": loss_func1, \\\"text_output_layer\\\": check_nonzero}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "increased-camera",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "def loss_func1(y_true, y_pred):\n",
    "    # tile sprite loss\n",
    "    r_loss=K.mean(K.square(y_true - y_pred), axis=[1,2,3])\n",
    "    loss  =  r_loss\n",
    "    return loss\n",
    "\n",
    "    \n",
    "def loss_func4(y_true,y_pred):\n",
    "    # multilabel text weighted bce\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\n",
    "    weighted_array=bce_array*tensor_from_list\n",
    "    bce_sum=K.sum(weighted_array,axis=1)\n",
    "    loss=bce_sum/13.0\n",
    "    return loss\n",
    "\n",
    "    \n",
    "losses ={'image_output_layer':loss_func1,\n",
    "          'text_output_layer':loss_func4,\n",
    "}\n",
    "\n",
    "\n",
    "#tweak loss weights\n",
    "lossWeights={'image_output_layer':0.1,\n",
    "          'text_output_layer':0.9  \n",
    "        }\n",
    "\n",
    "\n",
    "def check_nonzero(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric\n",
    "    Returns sum of all embeddings\n",
    "    \"\"\"\n",
    "    return(K.sum(K.cast(y_pred > 0.4, 'int32')))\n",
    "\n",
    "accuracy={\n",
    "    'image_output_layer':loss_func1,\n",
    "    'text_output_layer': check_nonzero\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "id": "median-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from keras import metrics\\n\\nae_sep_output.compile(\\n    optimizer=\\\"adam\\\", loss=losses, loss_weights=lossWeights, metrics=accuracy\\n)\";\n",
       "                var nbb_formatted_code = \"from keras import metrics\\n\\nae_sep_output.compile(\\n    optimizer=\\\"adam\\\", loss=losses, loss_weights=lossWeights, metrics=accuracy\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "median-bandwidth",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "from keras import metrics\n",
    "\n",
    "ae_sep_output.compile(\n",
    "    optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics=accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": null,
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "id": "rapid-chassis",
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "732/732 [==============================] - 22s 30ms/step - loss: 35.7754 - image_output_layer_loss: 333.3448 - text_output_layer_loss: 2.7122 - image_output_layer_loss_func1: 333.3448 - text_output_layer_check_nonzero: 45.3415 - val_loss: 30.0829 - val_image_output_layer_loss: 274.6573 - val_text_output_layer_loss: 2.9080 - val_image_output_layer_loss_func1: 274.6573 - val_text_output_layer_check_nonzero: 45.4262\n",
      "Epoch 2/5\n",
      "732/732 [==============================] - 23s 31ms/step - loss: 31.6668 - image_output_layer_loss: 299.5963 - text_output_layer_loss: 1.8968 - image_output_layer_loss_func1: 299.5963 - text_output_layer_check_nonzero: 45.3402 - val_loss: 30.1324 - val_image_output_layer_loss: 266.3271 - val_text_output_layer_loss: 3.8886 - val_image_output_layer_loss_func1: 266.3271 - val_text_output_layer_check_nonzero: 45.4208\n",
      "Epoch 3/5\n",
      "732/732 [==============================] - 24s 33ms/step - loss: 27.7069 - image_output_layer_loss: 266.8893 - text_output_layer_loss: 1.1311 - image_output_layer_loss_func1: 266.8893 - text_output_layer_check_nonzero: 45.3415 - val_loss: 26.2930 - val_image_output_layer_loss: 236.1802 - val_text_output_layer_loss: 2.9722 - val_image_output_layer_loss_func1: 236.1802 - val_text_output_layer_check_nonzero: 45.4262\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# with loss func 2 that is by using in built cross-entropy loss\\n\\nes = EarlyStopping(\\n    monitor=\\\"val_text_output_layer_loss\\\", mode=\\\"min\\\", verbose=1, patience=2\\n)\\n\\nae_history = ae_sep_output.fit(\\n    [train_image_batch, train_text_batch],\\n    [output_image_batch, output_text_batch],\\n    epochs=5,\\n    batch_size=25,\\n    shuffle=True,\\n    validation_split=0.2,\\n    callbacks=[es],\\n)\";\n",
       "                var nbb_formatted_code = \"# with loss func 2 that is by using in built cross-entropy loss\\n\\nes = EarlyStopping(\\n    monitor=\\\"val_text_output_layer_loss\\\", mode=\\\"min\\\", verbose=1, patience=2\\n)\\n\\nae_history = ae_sep_output.fit(\\n    [train_image_batch, train_text_batch],\\n    [output_image_batch, output_text_batch],\\n    epochs=5,\\n    batch_size=25,\\n    shuffle=True,\\n    validation_split=0.2,\\n    callbacks=[es],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "# with loss func 2 that is by using in built cross-entropy loss\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_text_output_layer_loss\", mode=\"min\", verbose=1, patience=2\n",
    ")\n",
    "\n",
    "ae_history = ae_sep_output.fit(\n",
    "    [train_image_batch, train_text_batch],\n",
    "    [output_image_batch, output_text_batch],\n",
    "    epochs=5,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "olympic-swiss",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
=======
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "id": "surprising-representative",
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_dense (Dense)             (None, 4096)         1052672     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_reshape (Reshape)         (None, 16, 16, 16)   0           image_dense[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv1 (Conv2DTranspose) (None, 16, 16, 16)   2320        image_reshape[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm1 (BatchNormalizati (None, 16, 16, 16)   64          idecode_conv1[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu1 (ReLU)            (None, 16, 16, 16)   0           idecode_norm1[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv2 (Conv2DTranspose) (None, 16, 16, 32)   4640        idecode_relu1[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense1 (Dense)          (None, 16)           4112        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm2 (BatchNormalizati (None, 16, 16, 32)   128         idecode_conv2[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_reshape (Reshape)          (None, 16)           0           tdecode_dense1[3][0]             \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu2 (ReLU)            (None, 16, 16, 32)   0           idecode_norm2[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense2 (Dense)          (None, 32)           544         text_reshape[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "image_output_layer (Conv2DTrans (None, 16, 16, 3)    867         idecode_relu2[3][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_output_layer (Dense)       (None, 13)           429         tdecode_dense2[3][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,065,776\n",
      "Trainable params: 1,065,680\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# build the inference model\\n\\ndecoder_input = Input(shape=(256,))\\n\\nd_dense = ae_sep_output.get_layer(\\\"image_dense\\\")(decoder_input)\\nd_reshape = ae_sep_output.get_layer(\\\"image_reshape\\\")(d_dense)\\nd_conv1 = ae_sep_output.get_layer(\\\"idecode_conv1\\\")(d_reshape)\\nd_norm1 = ae_sep_output.get_layer(\\\"idecode_norm1\\\")(d_conv1)\\nd_relu1 = ae_sep_output.get_layer(\\\"idecode_relu1\\\")(d_norm1)\\nd_conv2 = ae_sep_output.get_layer(\\\"idecode_conv2\\\")(d_relu1)\\nd_norm2 = ae_sep_output.get_layer(\\\"idecode_norm2\\\")(d_conv2)\\nd_relu2 = ae_sep_output.get_layer(\\\"idecode_relu2\\\")(d_norm2)\\nd_image_output = ae_sep_output.get_layer(\\\"image_output_layer\\\")(d_relu2)\\n\\nt_dense = ae_sep_output.get_layer(\\\"tdecode_dense1\\\")(decoder_input)\\nt_reshape = ae_sep_output.get_layer(\\\"text_reshape\\\")(t_dense)\\nt_dense2 = ae_sep_output.get_layer(\\\"tdecode_dense2\\\")(t_reshape)\\nd_text_output = ae_sep_output.get_layer(\\\"text_output_layer\\\")(t_dense2)\\n\\ndecoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])\\n\\ndecoder_model.summary()\";\n",
       "                var nbb_formatted_code = \"# build the inference model\\n\\ndecoder_input = Input(shape=(256,))\\n\\nd_dense = ae_sep_output.get_layer(\\\"image_dense\\\")(decoder_input)\\nd_reshape = ae_sep_output.get_layer(\\\"image_reshape\\\")(d_dense)\\nd_conv1 = ae_sep_output.get_layer(\\\"idecode_conv1\\\")(d_reshape)\\nd_norm1 = ae_sep_output.get_layer(\\\"idecode_norm1\\\")(d_conv1)\\nd_relu1 = ae_sep_output.get_layer(\\\"idecode_relu1\\\")(d_norm1)\\nd_conv2 = ae_sep_output.get_layer(\\\"idecode_conv2\\\")(d_relu1)\\nd_norm2 = ae_sep_output.get_layer(\\\"idecode_norm2\\\")(d_conv2)\\nd_relu2 = ae_sep_output.get_layer(\\\"idecode_relu2\\\")(d_norm2)\\nd_image_output = ae_sep_output.get_layer(\\\"image_output_layer\\\")(d_relu2)\\n\\nt_dense = ae_sep_output.get_layer(\\\"tdecode_dense1\\\")(decoder_input)\\nt_reshape = ae_sep_output.get_layer(\\\"text_reshape\\\")(t_dense)\\nt_dense2 = ae_sep_output.get_layer(\\\"tdecode_dense2\\\")(t_reshape)\\nd_text_output = ae_sep_output.get_layer(\\\"text_output_layer\\\")(t_dense2)\\n\\ndecoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])\\n\\ndecoder_model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "# build the inference model\n",
    "\n",
    "decoder_input = Input(shape=(256,))\n",
    "\n",
    "d_dense = ae_sep_output.get_layer(\"image_dense\")(decoder_input)\n",
    "d_reshape = ae_sep_output.get_layer(\"image_reshape\")(d_dense)\n",
    "d_conv1 = ae_sep_output.get_layer(\"idecode_conv1\")(d_reshape)\n",
    "d_norm1 = ae_sep_output.get_layer(\"idecode_norm1\")(d_conv1)\n",
    "d_relu1 = ae_sep_output.get_layer(\"idecode_relu1\")(d_norm1)\n",
    "d_conv2 = ae_sep_output.get_layer(\"idecode_conv2\")(d_relu1)\n",
    "d_norm2 = ae_sep_output.get_layer(\"idecode_norm2\")(d_conv2)\n",
    "d_relu2 = ae_sep_output.get_layer(\"idecode_relu2\")(d_norm2)\n",
    "d_image_output = ae_sep_output.get_layer(\"image_output_layer\")(d_relu2)\n",
    "\n",
    "t_dense = ae_sep_output.get_layer(\"tdecode_dense1\")(decoder_input)\n",
    "t_reshape = ae_sep_output.get_layer(\"text_reshape\")(t_dense)\n",
    "t_dense2 = ae_sep_output.get_layer(\"tdecode_dense2\")(t_reshape)\n",
    "d_text_output = ae_sep_output.get_layer(\"text_output_layer\")(t_dense2)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "id": "french-arrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Entire Model to disk\n",
      "Saved Encoder Model to disk\n",
      "Saved Decoder Model to disk\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"## save model weights, multilabel binarizer\\n\\nimport pickle\\n\\n# saving\\nwith open(\\\"model_tokenizer.pickle\\\", \\\"wb\\\") as handle:\\n    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n## saving the entire architecture model\\nmodel_json = ae_sep_output.to_json()\\nwith open(\\\"autoencoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nae_sep_output.save_weights(\\\"autoencoder_model.h5\\\")\\nprint(\\\"Saved Entire Model to disk\\\")\\n\\n## saving the encoder part\\nmodel_json = encoding_model.to_json()\\nwith open(\\\"encoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nencoding_model.save_weights(\\\"encoder_model.h5\\\")\\nprint(\\\"Saved Encoder Model to disk\\\")\\n## saving the encoder part\\n\\nmodel_json = decoder_model.to_json()\\nwith open(\\\"decoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\ndecoder_model.save_weights(\\\"decoder_model.h5\\\")\\nprint(\\\"Saved Decoder Model to disk\\\")\";\n",
       "                var nbb_formatted_code = \"## save model weights, multilabel binarizer\\n\\nimport pickle\\n\\n# saving\\nwith open(\\\"model_tokenizer.pickle\\\", \\\"wb\\\") as handle:\\n    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n## saving the entire architecture model\\nmodel_json = ae_sep_output.to_json()\\nwith open(\\\"autoencoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nae_sep_output.save_weights(\\\"autoencoder_model.h5\\\")\\nprint(\\\"Saved Entire Model to disk\\\")\\n\\n## saving the encoder part\\nmodel_json = encoding_model.to_json()\\nwith open(\\\"encoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nencoding_model.save_weights(\\\"encoder_model.h5\\\")\\nprint(\\\"Saved Encoder Model to disk\\\")\\n## saving the encoder part\\n\\nmodel_json = decoder_model.to_json()\\nwith open(\\\"decoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\ndecoder_model.save_weights(\\\"decoder_model.h5\\\")\\nprint(\\\"Saved Decoder Model to disk\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "french-arrow",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "## save model weights, multilabel binarizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(\"model_tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "## saving the entire architecture model\n",
    "model_json = ae_sep_output.to_json()\n",
    "with open(\"autoencoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "ae_sep_output.save_weights(\"autoencoder_model.h5\")\n",
    "print(\"Saved Entire Model to disk\")\n",
    "\n",
    "## saving the encoder part\n",
    "model_json = encoding_model.to_json()\n",
    "with open(\"encoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "encoding_model.save_weights(\"encoder_model.h5\")\n",
    "print(\"Saved Encoder Model to disk\")\n",
    "## saving the encoder part\n",
    "\n",
    "model_json = decoder_model.to_json()\n",
    "with open(\"decoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "decoder_model.save_weights(\"decoder_model.h5\")\n",
    "print(\"Saved Decoder Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "id": "reflected-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y is Ready. Shape :  (2540, 13)\n",
      "True Y is Ready. Shape : (2540, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"predicted_image, predicted_text = ae_sep_output.predict(\\n    [test_image_batch, test_text_batch]\\n)\\ny_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\\ny_pred = np.array(y_pred)\\nprint(\\\"Predicted Y is Ready. Shape : \\\", y_pred.shape)\\n\\ny_true = test_text_batch\\ny_true = np.array(y_true)\\nprint(\\\"True Y is Ready. Shape :\\\", y_true.shape)\";\n",
       "                var nbb_formatted_code = \"predicted_image, predicted_text = ae_sep_output.predict(\\n    [test_image_batch, test_text_batch]\\n)\\ny_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\\ny_pred = np.array(y_pred)\\nprint(\\\"Predicted Y is Ready. Shape : \\\", y_pred.shape)\\n\\ny_true = test_text_batch\\ny_true = np.array(y_true)\\nprint(\\\"True Y is Ready. Shape :\\\", y_true.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "reflected-partner",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "id": "indirect-abuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAACAklEQVR4nFWNS2tUQRCF61RX33ndPDBZJESCK0F8oAYU/BvudCMu9P+406V/RsGVkGyMRoSgEmKSmWRm7p3uruNiJgarDlWLU+crbG5uUgQgREgRgVwVRTAfIqIiJBVCd5+b/3RZEM4doXAuUxEVgsr/4Zf8eU4oEkgtbrogUEQESiGu+ItbCAEJUCXMnaAIABHOGws4LpcAgJTkMv8AkiCwQC+ycwAEAFXoUhQFwQSggiBYvEjOVIspZYtBvISA2AuI8Ey2gNNI6Q1kbUvqOnfrGKG5zNomER5gSN6v40VOkzP78Z3emCVy67q/elbfu115z5zaH3AmBiNTmJ6X9X44HI6/7Vbv3p/+OaCahrXV2ZMHvnM3D1ZKJ0YT52w2GZ7BCw2DenL/Tn68w9WN3Imw4jIzl37v68ngzduf+/vTbmm16pbSWjw+9/Lw5uT5y61kqjEERIuUaCwBw9Td3Ytfdgd1qgI0M2rE1ItOp0+bnmtOk8a4ZAGIWfpkbqYcneU2Nm1LaFty6FTeNrWma6UdJVoLFxiFyQfj0l9Z5d2dWK2LpsBgktirkZvOrUddLmtzJKI2zRMr5PnQJ6flxra/frHcsIfCi2LM7cbW8mjE7Y3OUu2/D8MMnUbEzHQ8LB8/nMyaECvp16mkHHKIbYPjtiq9XwfN3tg/f5LhUVF0/wJhfja5n7VqgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=16x16 at 0x7FB55C3472B0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"array_to_img(predicted_image[24])\";\n",
       "                var nbb_formatted_code = \"array_to_img(predicted_image[24])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "modern-midwest",
   "metadata": {},
   "outputs": [],
>>>>>>> 313595c9947f6e24834176741f5ba4ec9aabc23b
   "source": [
    "array_to_img(predicted_image[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_divide(num, den):\n",
    "    count = 0\n",
    "    result = {}\n",
    "    for idx in range(len(num)):\n",
    "        if num[idx] == den[idx] == 0:\n",
    "            continue\n",
    "        elif num[idx] != 0 and den[idx] != 0:\n",
    "            result[idx] = num[idx] / den[idx]\n",
    "            count += 1\n",
    "        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\n",
    "            count += 1\n",
    "            result[idx] = 0.0\n",
    "    return result, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_embeddings",
   "language": "python",
   "name": "tile_embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
