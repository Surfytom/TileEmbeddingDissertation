{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atomic-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.utils import shuffle\\nimport json\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import os\\nimport glob\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.utils import shuffle\\nimport json\\nfrom keras.preprocessing import sequence, image\\nfrom keras.preprocessing.image import array_to_img, save_img, img_to_array\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\n\\nfrom keras.layers import (\\n    Flatten,\\n    Dense,\\n    Input,\\n    Activation,\\n    BatchNormalization,\\n    Conv2D,\\n    MaxPool2D,\\n    Dropout,\\n    UpSampling2D,\\n    Lambda,\\n)\\n\\nfrom keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\\nfrom keras.models import Model\\n\\nfrom keras.optimizers import Adam\\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\\nfrom keras import backend as K\\n\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\\nfrom collections import Counter\\n\\nfrom evaluation_metrics.multilabel.example_based import (\\n    hamming_loss,\\n    example_based_accuracy,\\n    example_based_precision,\\n    example_based_recall,\\n)\\n\\nfrom evaluation_metrics.multilabel.label_based import (\\n    accuracy_macro,\\n    precision_macro,\\n    recall_macro,\\n    accuracy_micro,\\n    precision_micro,\\n    recall_micro,\\n)\\n\\nfrom evaluation_metrics.multilabel.alpha_score import alpha_score\\nfrom data_loading.load_data import get_tile_data\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "from evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "\n",
    "from evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from data_loading.load_data import get_tile_data\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "animated-speech",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games detected in the parent folder ['lode_runner', 'kid_icarus', 'megaman', 'smb', 'loz']\n",
      "Current Game lode_runner\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/lode_runner\n",
      "Current Game kid_icarus\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/kid_icarus\n",
      "Current Game megaman\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/megaman\n",
      "Current Game smb\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/smb\n",
      "Current Game loz\n",
      "Reading mappings\n",
      "Json File Loaded\n",
      "Reading Sprite Data From ../data/context_data/loz\n",
      "\n",
      "The size of total data is (25394, 5)\n",
      "\n",
      "The size of the train data is  (22854, 5)\n",
      "The size of the test data is  (2540, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"##loading train and testing data\\n\\ndata_directory = \\\"../data/context_data/\\\"\\njson_directory = \\\"../data/json_files_trimmed_features/\\\"\\ndata = get_tile_data(data_directory, json_directory)\\nprint(\\\"\\\\nThe size of total data is\\\", data.shape)\\ndata = shuffle(data)\\n\\n# split into train-test\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\\n\\nprint(\\\"\\\\nThe size of the train data is \\\", train_data.shape)\\nprint(\\\"The size of the test data is \\\", test_data.shape)\";\n",
       "                var nbb_formatted_code = \"##loading train and testing data\\n\\ndata_directory = \\\"../data/context_data/\\\"\\njson_directory = \\\"../data/json_files_trimmed_features/\\\"\\ndata = get_tile_data(data_directory, json_directory)\\nprint(\\\"\\\\nThe size of total data is\\\", data.shape)\\ndata = shuffle(data)\\n\\n# split into train-test\\nfrom sklearn.model_selection import train_test_split\\n\\ntrain_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\\n\\nprint(\\\"\\\\nThe size of the train data is \\\", train_data.shape)\\nprint(\\\"The size of the test data is \\\", test_data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##loading train and testing data\n",
    "\n",
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "data = get_tile_data(data_directory, json_directory)\n",
    "print(\"\\nThe size of total data is\", data.shape)\n",
    "data = shuffle(data)\n",
    "\n",
    "# split into train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\n",
    "\n",
    "print(\"\\nThe size of the train data is \", train_data.shape)\n",
    "print(\"The size of the test data is \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incomplete-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature Dictionary..\n",
      "The feature dictionary has size 13\n",
      "Printing Feature classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['block', 'breakable', 'climbable', 'collectable', 'element',\n",
       "       'empty', 'hazard', 'moving', 'openable', 'passable', 'pipe',\n",
       "       'solid', 'wall'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"#Feature Dictionary\\nprint(\\\"Building feature Dictionary..\\\")\\nmlb = MultiLabelBinarizer()\\ncombined_features=np.concatenate([train_data['features'],test_data['features']],axis=0)\\nmlb_model = mlb.fit(combined_features)\\ntotal_features=len(mlb_model.classes_)\\nprint(\\\"The feature dictionary has size\\\",total_features)\\nprint(\\\"Printing Feature classes\\\")\\ndisplay(mlb_model.classes_)\";\n",
       "                var nbb_formatted_code = \"# Feature Dictionary\\nprint(\\\"Building feature Dictionary..\\\")\\nmlb = MultiLabelBinarizer()\\ncombined_features = np.concatenate(\\n    [train_data[\\\"features\\\"], test_data[\\\"features\\\"]], axis=0\\n)\\nmlb_model = mlb.fit(combined_features)\\ntotal_features = len(mlb_model.classes_)\\nprint(\\\"The feature dictionary has size\\\", total_features)\\nprint(\\\"Printing Feature classes\\\")\\ndisplay(mlb_model.classes_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Dictionary\n",
    "print(\"Building feature Dictionary..\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "combined_features = np.concatenate(\n",
    "    [train_data[\"features\"], test_data[\"features\"]], axis=0\n",
    ")\n",
    "mlb_model = mlb.fit(combined_features)\n",
    "total_features = len(mlb_model.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "print(\"Printing Feature classes\")\n",
    "display(mlb_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "toxic-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Training Batches\n",
      "Training Data Ready\n",
      "Train Image batch shape (22854, 48, 48, 3)\n",
      "Train Text batch shape (22854, 13)\n",
      "\n",
      "\n",
      "Output Image batch shape (22854, 16, 16, 3)\n",
      "Output Text batch shape (22854, 13)\n",
      "Building Testing Batches\n",
      "\n",
      "\n",
      "Testing Data Ready\n",
      "Train Image batch shape (2540, 48, 48, 3)\n",
      "Train Text batch shape (2540, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Build Input Output Training Batches\\nprint(\\\"Building Training Batches\\\")\\n\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntrain_image_batch = []\\nfor train_path in train_data[\\\"image_path\\\"]:\\n    tile = image.load_img(train_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    train_image_batch.append(tile_sprite)\\ntrain_image_batch = np.array(train_image_batch)\\ntrain_text_batch = []\\nfor i in range(len(train_data[\\\"features\\\"])):\\n    text_ = mlb.transform(train_data[\\\"features\\\"][i : i + 1])\\n    train_text_batch.append(text_)\\ntrain_text_batch = np.array(train_text_batch).reshape(train_data.shape[0], total_features)\\n\\noutput_image_batch=[]\\nfor i in range(len(train_image_batch)):\\n    current_image = train_image_batch[i]\\n    current_image_centre=train_image_batch[i][16:16+16,16:16+16,:]\\n    output_image_batch.append(current_image_centre)    \\noutput_image_batch=np.array(output_image_batch)\\noutput_text_batch=[]\\nfor i in range(len(train_text_batch)):\\n    current_text = train_text_batch[i]\\n    output_text_batch.append(current_text)\\noutput_text_batch=np.array(output_text_batch)\\nprint(\\\"Training Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\",train_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\",train_text_batch.shape)\\nprint(\\\"\\\\n\\\\nOutput Image batch shape\\\",output_image_batch.shape)\\nprint(\\\"Output Text batch shape\\\",output_text_batch.shape)\\n\\n\\n# Build Input Output Test Batches\\nprint(\\\"Building Testing Batches\\\")\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntest_image_batch = []\\nfor test_path in test_data[\\\"image_path\\\"]:\\n    tile = image.load_img(test_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    test_image_batch.append(tile_sprite)\\ntest_image_batch = np.array(test_image_batch)\\ntest_text_batch = []\\nfor i in range(len(test_data[\\\"features\\\"])):\\n    text_ = mlb.transform(test_data[\\\"features\\\"][i : i + 1])\\n    test_text_batch.append(text_)\\ntest_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\\nprint(\\\"\\\\n\\\\nTesting Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\",test_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\",test_text_batch.shape)\";\n",
       "                var nbb_formatted_code = \"# Build Input Output Training Batches\\nprint(\\\"Building Training Batches\\\")\\n\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntrain_image_batch = []\\nfor train_path in train_data[\\\"image_path\\\"]:\\n    tile = image.load_img(train_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    train_image_batch.append(tile_sprite)\\ntrain_image_batch = np.array(train_image_batch)\\ntrain_text_batch = []\\nfor i in range(len(train_data[\\\"features\\\"])):\\n    text_ = mlb.transform(train_data[\\\"features\\\"][i : i + 1])\\n    train_text_batch.append(text_)\\ntrain_text_batch = np.array(train_text_batch).reshape(\\n    train_data.shape[0], total_features\\n)\\n\\noutput_image_batch = []\\nfor i in range(len(train_image_batch)):\\n    current_image = train_image_batch[i]\\n    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    output_image_batch.append(current_image_centre)\\noutput_image_batch = np.array(output_image_batch)\\noutput_text_batch = []\\nfor i in range(len(train_text_batch)):\\n    current_text = train_text_batch[i]\\n    output_text_batch.append(current_text)\\noutput_text_batch = np.array(output_text_batch)\\nprint(\\\"Training Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", train_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", train_text_batch.shape)\\nprint(\\\"\\\\n\\\\nOutput Image batch shape\\\", output_image_batch.shape)\\nprint(\\\"Output Text batch shape\\\", output_text_batch.shape)\\n\\n\\n# Build Input Output Test Batches\\nprint(\\\"Building Testing Batches\\\")\\n\\\"\\\"\\\"Note : Add Generators\\\"\\\"\\\"\\ntest_image_batch = []\\nfor test_path in test_data[\\\"image_path\\\"]:\\n    tile = image.load_img(test_path, target_size=(48, 48))\\n    tile_sprite = image.img_to_array(tile)\\n    test_image_batch.append(tile_sprite)\\ntest_image_batch = np.array(test_image_batch)\\ntest_text_batch = []\\nfor i in range(len(test_data[\\\"features\\\"])):\\n    text_ = mlb.transform(test_data[\\\"features\\\"][i : i + 1])\\n    test_text_batch.append(text_)\\ntest_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\\nprint(\\\"\\\\n\\\\nTesting Data Ready\\\")\\nprint(\\\"Train Image batch shape\\\", test_image_batch.shape)\\nprint(\\\"Train Text batch shape\\\", test_text_batch.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Input Output Training Batches\n",
    "print(\"Building Training Batches\")\n",
    "\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "train_image_batch = []\n",
    "for train_path in train_data[\"image_path\"]:\n",
    "    tile = image.load_img(train_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    train_image_batch.append(tile_sprite)\n",
    "train_image_batch = np.array(train_image_batch)\n",
    "train_text_batch = []\n",
    "for i in range(len(train_data[\"features\"])):\n",
    "    text_ = mlb.transform(train_data[\"features\"][i : i + 1])\n",
    "    train_text_batch.append(text_)\n",
    "train_text_batch = np.array(train_text_batch).reshape(\n",
    "    train_data.shape[0], total_features\n",
    ")\n",
    "\n",
    "output_image_batch = []\n",
    "for i in range(len(train_image_batch)):\n",
    "    current_image = train_image_batch[i]\n",
    "    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    output_image_batch.append(current_image_centre)\n",
    "output_image_batch = np.array(output_image_batch)\n",
    "output_text_batch = []\n",
    "for i in range(len(train_text_batch)):\n",
    "    current_text = train_text_batch[i]\n",
    "    output_text_batch.append(current_text)\n",
    "output_text_batch = np.array(output_text_batch)\n",
    "print(\"Training Data Ready\")\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "\n",
    "# Build Input Output Test Batches\n",
    "print(\"Building Testing Batches\")\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "test_image_batch = []\n",
    "for test_path in test_data[\"image_path\"]:\n",
    "    tile = image.load_img(test_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    test_image_batch.append(tile_sprite)\n",
    "test_image_batch = np.array(test_image_batch)\n",
    "test_text_batch = []\n",
    "for i in range(len(test_data[\"features\"])):\n",
    "    text_ = mlb.transform(test_data[\"features\"][i : i + 1])\n",
    "    test_text_batch.append(text_)\n",
    "test_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\n",
    "print(\"\\n\\nTesting Data Ready\")\n",
    "print(\"Train Image batch shape\", test_image_batch.shape)\n",
    "print(\"Train Text batch shape\", test_text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "earned-keyboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# model definition\\n\\nlatent_dim = 128\\nbatch_size = 1\\n\\n# image encoder\\nimage_encoder_input = Input(shape=(48, 48, 3), name=\\\"image_input\\\")\\n\\nimage_encoder_conv_layer1 = Conv2D(\\n    32, strides=3, kernel_size=(3, 3), name=\\\"iencode_conv1\\\"\\n)(image_encoder_input)\\nimage_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\\nimage_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\\n\\nimage_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv2\\\")(\\n    image_encoder_actv_layer1\\n)\\nimage_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\\nimage_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\\n\\nimage_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv3\\\")(\\n    image_encoder_actv_layer2\\n)\\nimage_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\\nimage_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\\n\\nimage_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\\nimage_flatten = Flatten(name=\\\"image_flatten_layer\\\")(image_encoder_actv_layer3)\\n\\n\\n# text encoder\\ntext_encoder_input = Input(shape=(13,))\\n\\ntext_encoder_dense_layer1 = Dense(32, activation=\\\"tanh\\\", name=\\\"tencode_dense1\\\")(\\n    text_encoder_input\\n)\\ntext_encoder_dense_layer2 = Dense(16, activation=\\\"tanh\\\", name=\\\"tencode_dense2\\\")(\\n    text_encoder_dense_layer1\\n)\\ntext_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\\n\\n# image-text concatenation\\nimage_text_concat = Concatenate(name=\\\"image_text_concatenation\\\")(\\n    [image_flatten, text_encoder_dense_layer2]\\n)\\n\\nimage_text_concat = Dense(256, activation=\\\"tanh\\\", name=\\\"embedding_dense_1\\\")(\\n    image_text_concat\\n)\\n\\n\\n##\\nencoding_model = Model(\\n    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\\n)\\n\\n# decoder for image\\n\\n# decoder_input=Input(shape=(512,))\\n\\nimage_y = Dense(units=np.prod(image_shape_before_flatten), name=\\\"image_dense\\\")(\\n    image_text_concat\\n)\\nimage_y = Reshape(target_shape=image_shape_before_flatten, name=\\\"image_reshape\\\")(\\n    image_y\\n)\\n\\nimage_decoder_convt_layer1 = Conv2DTranspose(\\n    16, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv1\\\"\\n)(image_y)\\nimage_decoder_norm_layer1 = BatchNormalization(name=\\\"idecode_norm1\\\")(\\n    image_decoder_convt_layer1\\n)\\nimage_decoder_actv_layer1 = ReLU(name=\\\"idecode_relu1\\\")(image_decoder_norm_layer1)\\n\\n\\nimage_decoder_convt_layer2 = Conv2DTranspose(\\n    32, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv2\\\"\\n)(image_decoder_actv_layer1)\\nimage_decoder_norm_layer2 = BatchNormalization(name=\\\"idecode_norm2\\\")(\\n    image_decoder_convt_layer2\\n)\\nimage_decoder_actv_layer2 = ReLU(name=\\\"idecode_relu2\\\")(image_decoder_norm_layer2)\\n\\nimage_decoder_output = Conv2DTranspose(\\n    3, (3, 3), padding=\\\"same\\\", name=\\\"image_output_layer\\\"\\n)(image_decoder_actv_layer2)\\n\\n\\n# decoder for text\\n\\ntext_decoder_dense_layer1 = Dense(16, activation=\\\"tanh\\\", name=\\\"tdecode_dense1\\\")(\\n    image_text_concat\\n)\\ntext_reshape = Reshape(target_shape=text_shape_before_concat, name=\\\"text_reshape\\\")(\\n    text_decoder_dense_layer1\\n)\\ntext_decoder_dense_layer2 = Dense(32, activation=\\\"tanh\\\", name=\\\"tdecode_dense2\\\")(\\n    text_reshape\\n)\\n\\ntext_decoder_output = Dense(13, activation=\\\"sigmoid\\\", name=\\\"text_output_layer\\\")(\\n    text_decoder_dense_layer2\\n)\\n\\n\\n# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\\n\\n\\nae_sep_output = Model(\\n    [image_encoder_input, text_encoder_input],\\n    [image_decoder_output, text_decoder_output],\\n)\";\n",
       "                var nbb_formatted_code = \"# model definition\\n\\nlatent_dim = 128\\nbatch_size = 1\\n\\n# image encoder\\nimage_encoder_input = Input(shape=(48, 48, 3), name=\\\"image_input\\\")\\n\\nimage_encoder_conv_layer1 = Conv2D(\\n    32, strides=3, kernel_size=(3, 3), name=\\\"iencode_conv1\\\"\\n)(image_encoder_input)\\nimage_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\\nimage_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\\n\\nimage_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv2\\\")(\\n    image_encoder_actv_layer1\\n)\\nimage_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\\nimage_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\\n\\nimage_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\\\"same\\\", name=\\\"iencode_conv3\\\")(\\n    image_encoder_actv_layer2\\n)\\nimage_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\\nimage_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\\n\\nimage_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\\nimage_flatten = Flatten(name=\\\"image_flatten_layer\\\")(image_encoder_actv_layer3)\\n\\n\\n# text encoder\\ntext_encoder_input = Input(shape=(13,))\\n\\ntext_encoder_dense_layer1 = Dense(32, activation=\\\"tanh\\\", name=\\\"tencode_dense1\\\")(\\n    text_encoder_input\\n)\\ntext_encoder_dense_layer2 = Dense(16, activation=\\\"tanh\\\", name=\\\"tencode_dense2\\\")(\\n    text_encoder_dense_layer1\\n)\\ntext_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\\n\\n# image-text concatenation\\nimage_text_concat = Concatenate(name=\\\"image_text_concatenation\\\")(\\n    [image_flatten, text_encoder_dense_layer2]\\n)\\n\\nimage_text_concat = Dense(256, activation=\\\"tanh\\\", name=\\\"embedding_dense_1\\\")(\\n    image_text_concat\\n)\\n\\n\\n##\\nencoding_model = Model(\\n    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\\n)\\n\\n# decoder for image\\n\\n# decoder_input=Input(shape=(512,))\\n\\nimage_y = Dense(units=np.prod(image_shape_before_flatten), name=\\\"image_dense\\\")(\\n    image_text_concat\\n)\\nimage_y = Reshape(target_shape=image_shape_before_flatten, name=\\\"image_reshape\\\")(\\n    image_y\\n)\\n\\nimage_decoder_convt_layer1 = Conv2DTranspose(\\n    16, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv1\\\"\\n)(image_y)\\nimage_decoder_norm_layer1 = BatchNormalization(name=\\\"idecode_norm1\\\")(\\n    image_decoder_convt_layer1\\n)\\nimage_decoder_actv_layer1 = ReLU(name=\\\"idecode_relu1\\\")(image_decoder_norm_layer1)\\n\\n\\nimage_decoder_convt_layer2 = Conv2DTranspose(\\n    32, (3, 3), padding=\\\"same\\\", name=\\\"idecode_conv2\\\"\\n)(image_decoder_actv_layer1)\\nimage_decoder_norm_layer2 = BatchNormalization(name=\\\"idecode_norm2\\\")(\\n    image_decoder_convt_layer2\\n)\\nimage_decoder_actv_layer2 = ReLU(name=\\\"idecode_relu2\\\")(image_decoder_norm_layer2)\\n\\nimage_decoder_output = Conv2DTranspose(\\n    3, (3, 3), padding=\\\"same\\\", name=\\\"image_output_layer\\\"\\n)(image_decoder_actv_layer2)\\n\\n\\n# decoder for text\\n\\ntext_decoder_dense_layer1 = Dense(16, activation=\\\"tanh\\\", name=\\\"tdecode_dense1\\\")(\\n    image_text_concat\\n)\\ntext_reshape = Reshape(target_shape=text_shape_before_concat, name=\\\"text_reshape\\\")(\\n    text_decoder_dense_layer1\\n)\\ntext_decoder_dense_layer2 = Dense(32, activation=\\\"tanh\\\", name=\\\"tdecode_dense2\\\")(\\n    text_reshape\\n)\\n\\ntext_decoder_output = Dense(13, activation=\\\"sigmoid\\\", name=\\\"text_output_layer\\\")(\\n    text_decoder_dense_layer2\\n)\\n\\n\\n# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\\n\\n\\nae_sep_output = Model(\\n    [image_encoder_input, text_encoder_input],\\n    [image_decoder_output, text_decoder_output],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model definition\n",
    "\n",
    "latent_dim = 128\n",
    "batch_size = 1\n",
    "\n",
    "# image encoder\n",
    "image_encoder_input = Input(shape=(48, 48, 3), name=\"image_input\")\n",
    "\n",
    "image_encoder_conv_layer1 = Conv2D(\n",
    "    32, strides=3, kernel_size=(3, 3), name=\"iencode_conv1\"\n",
    ")(image_encoder_input)\n",
    "image_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\n",
    "image_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\n",
    "\n",
    "image_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\"same\", name=\"iencode_conv2\")(\n",
    "    image_encoder_actv_layer1\n",
    ")\n",
    "image_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\n",
    "image_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\n",
    "\n",
    "image_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\"same\", name=\"iencode_conv3\")(\n",
    "    image_encoder_actv_layer2\n",
    ")\n",
    "image_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\n",
    "image_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\n",
    "\n",
    "image_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\n",
    "image_flatten = Flatten(name=\"image_flatten_layer\")(image_encoder_actv_layer3)\n",
    "\n",
    "\n",
    "# text encoder\n",
    "text_encoder_input = Input(shape=(13,))\n",
    "\n",
    "text_encoder_dense_layer1 = Dense(32, activation=\"tanh\", name=\"tencode_dense1\")(\n",
    "    text_encoder_input\n",
    ")\n",
    "text_encoder_dense_layer2 = Dense(16, activation=\"tanh\", name=\"tencode_dense2\")(\n",
    "    text_encoder_dense_layer1\n",
    ")\n",
    "text_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\n",
    "\n",
    "# image-text concatenation\n",
    "image_text_concat = Concatenate(name=\"image_text_concatenation\")(\n",
    "    [image_flatten, text_encoder_dense_layer2]\n",
    ")\n",
    "\n",
    "image_text_concat = Dense(256, activation=\"tanh\", name=\"embedding_dense_1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "\n",
    "\n",
    "##\n",
    "encoding_model = Model(\n",
    "    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\n",
    ")\n",
    "\n",
    "# decoder for image\n",
    "\n",
    "# decoder_input=Input(shape=(512,))\n",
    "\n",
    "image_y = Dense(units=np.prod(image_shape_before_flatten), name=\"image_dense\")(\n",
    "    image_text_concat\n",
    ")\n",
    "image_y = Reshape(target_shape=image_shape_before_flatten, name=\"image_reshape\")(\n",
    "    image_y\n",
    ")\n",
    "\n",
    "image_decoder_convt_layer1 = Conv2DTranspose(\n",
    "    16, (3, 3), padding=\"same\", name=\"idecode_conv1\"\n",
    ")(image_y)\n",
    "image_decoder_norm_layer1 = BatchNormalization(name=\"idecode_norm1\")(\n",
    "    image_decoder_convt_layer1\n",
    ")\n",
    "image_decoder_actv_layer1 = ReLU(name=\"idecode_relu1\")(image_decoder_norm_layer1)\n",
    "\n",
    "\n",
    "image_decoder_convt_layer2 = Conv2DTranspose(\n",
    "    32, (3, 3), padding=\"same\", name=\"idecode_conv2\"\n",
    ")(image_decoder_actv_layer1)\n",
    "image_decoder_norm_layer2 = BatchNormalization(name=\"idecode_norm2\")(\n",
    "    image_decoder_convt_layer2\n",
    ")\n",
    "image_decoder_actv_layer2 = ReLU(name=\"idecode_relu2\")(image_decoder_norm_layer2)\n",
    "\n",
    "image_decoder_output = Conv2DTranspose(\n",
    "    3, (3, 3), padding=\"same\", name=\"image_output_layer\"\n",
    ")(image_decoder_actv_layer2)\n",
    "\n",
    "\n",
    "# decoder for text\n",
    "\n",
    "text_decoder_dense_layer1 = Dense(16, activation=\"tanh\", name=\"tdecode_dense1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "text_reshape = Reshape(target_shape=text_shape_before_concat, name=\"text_reshape\")(\n",
    "    text_decoder_dense_layer1\n",
    ")\n",
    "text_decoder_dense_layer2 = Dense(32, activation=\"tanh\", name=\"tdecode_dense2\")(\n",
    "    text_reshape\n",
    ")\n",
    "\n",
    "text_decoder_output = Dense(13, activation=\"sigmoid\", name=\"text_output_layer\")(\n",
    "    text_decoder_dense_layer2\n",
    ")\n",
    "\n",
    "\n",
    "# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\n",
    "\n",
    "\n",
    "ae_sep_output = Model(\n",
    "    [image_encoder_input, text_encoder_input],\n",
    "    [image_decoder_output, text_decoder_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recreational-newsletter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv1 (Conv2D)          (None, 16, 16, 32)   896         image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         iencode_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv2 (Conv2D)          (None, 16, 16, 32)   9248        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         iencode_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "iencode_conv3 (Conv2D)          (None, 16, 16, 16)   4624        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 16)   64          iencode_conv3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 16, 16, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tencode_dense1 (Dense)          (None, 32)           448         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_flatten_layer (Flatten)   (None, 4096)         0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tencode_dense2 (Dense)          (None, 16)           528         tencode_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "image_text_concatenation (Conca (None, 4112)         0           image_flatten_layer[0][0]        \n",
      "                                                                 tencode_dense2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_dense_1 (Dense)       (None, 256)          1052928     image_text_concatenation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "image_dense (Dense)             (None, 4096)         1052672     embedding_dense_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "image_reshape (Reshape)         (None, 16, 16, 16)   0           image_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv1 (Conv2DTranspose) (None, 16, 16, 16)   2320        image_reshape[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm1 (BatchNormalizati (None, 16, 16, 16)   64          idecode_conv1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu1 (ReLU)            (None, 16, 16, 16)   0           idecode_norm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv2 (Conv2DTranspose) (None, 16, 16, 32)   4640        idecode_relu1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense1 (Dense)          (None, 16)           4112        embedding_dense_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm2 (BatchNormalizati (None, 16, 16, 32)   128         idecode_conv2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_reshape (Reshape)          (None, 16)           0           tdecode_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu2 (ReLU)            (None, 16, 16, 32)   0           idecode_norm2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense2 (Dense)          (None, 32)           544         text_reshape[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "image_output_layer (Conv2DTrans (None, 16, 16, 3)    867         idecode_relu2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_output_layer (Dense)       (None, 13)           429         tdecode_dense2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 2,134,768\n",
      "Trainable params: 2,134,512\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"ae_sep_output.get_layer(\\\"tdecode_dense1\\\")\\nprint(ae_sep_output.summary())\";\n",
       "                var nbb_formatted_code = \"ae_sep_output.get_layer(\\\"tdecode_dense1\\\")\\nprint(ae_sep_output.summary())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ae_sep_output.get_layer(\"tdecode_dense1\")\n",
    "print(ae_sep_output.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "several-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Printing the TF-IDF for the labels\n",
      "\n",
      " {'block': 5.102030995146257, 'breakable': 2.6009420547751505, 'climbable': 2.770503717781291, 'collectable': 4.106430424814218, 'element': 5.581604075408143, 'empty': 2.0879495829240695, 'hazard': 4.798600565726337, 'moving': 6.177112786404172, 'openable': 6.382964840608321, 'passable': 1.6016029582018123, 'pipe': 6.441805340631255, 'solid': 1.830392057132616, 'wall': 5.243911582381701}\n",
      "\n",
      "Printing the weight normalised\n",
      "\n",
      "\n",
      "{'block': 0.0932289019467309, 'breakable': 0.04752675395826563, 'climbable': 0.05062513726275023, 'collectable': 0.07503639232891463, 'element': 0.10199209286394827, 'empty': 0.038152893841948456, 'hazard': 0.08768434806633386, 'moving': 0.11287376396290665, 'openable': 0.11663527795511663, 'passable': 0.029265930624459206, 'pipe': 0.11771046452539688, 'solid': 0.033446570940245716, 'wall': 0.09582147172298304}\n",
      "Weight Vector\n",
      "[5102.030995146257, 2600.9420547751506, 2770.503717781291, 4106.430424814218, 5581.604075408143, 2087.9495829240695, 4798.600565726338, 6177.112786404172, 6382.964840608321, 1601.6029582018123, 6441.805340631256, 1830.392057132616, 5243.911582381701]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mumu/.local/share/virtualenvs/tile_representation-VeDour9V/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\nfrom ast import literal_eval\\nimport tensorflow as tf\\n\\nvectorizer = TfidfVectorizer(stop_words=None)\\ntrain_data_copy = train_data\\ntrain_data_copy[\\\"features\\\"] = train_data_copy.features.apply(lambda x: str(x))\\nvectors = vectorizer.fit_transform(train_data_copy[\\\"features\\\"])\\n\\nidf = vectorizer.idf_\\n\\n# build the weight dictionary\\nnew_dict = {}\\nfor c in mlb.classes_:\\n    if c in vectorizer.vocabulary_.keys():\\n        new_dict[c] = idf[vectorizer.vocabulary_[c]]\\n    else:\\n        new_dict[c] = np.max(idf)\\nprint(\\\"\\\\n Printing the TF-IDF for the labels\\\\n\\\\n\\\", new_dict)\\n\\n\\nweight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\\n\\nprint(\\\"\\\\nPrinting the weight normalised\\\\n\\\\n\\\")\\nprint(weight_freq)\\n\\nweight_vector = [v * 1000 for v in new_dict.values()]\\n\\ntensor_from_list = tf.convert_to_tensor(weight_vector)\\ntensor_from_list = K.cast(tensor_from_list, \\\"float32\\\")\\n\\nprint(\\\"Weight Vector\\\")\\nprint(weight_vector)\";\n",
       "                var nbb_formatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\nfrom ast import literal_eval\\nimport tensorflow as tf\\n\\nvectorizer = TfidfVectorizer(stop_words=None)\\ntrain_data_copy = train_data\\ntrain_data_copy[\\\"features\\\"] = train_data_copy.features.apply(lambda x: str(x))\\nvectors = vectorizer.fit_transform(train_data_copy[\\\"features\\\"])\\n\\nidf = vectorizer.idf_\\n\\n# build the weight dictionary\\nnew_dict = {}\\nfor c in mlb.classes_:\\n    if c in vectorizer.vocabulary_.keys():\\n        new_dict[c] = idf[vectorizer.vocabulary_[c]]\\n    else:\\n        new_dict[c] = np.max(idf)\\nprint(\\\"\\\\n Printing the TF-IDF for the labels\\\\n\\\\n\\\", new_dict)\\n\\n\\nweight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\\n\\nprint(\\\"\\\\nPrinting the weight normalised\\\\n\\\\n\\\")\\nprint(weight_freq)\\n\\nweight_vector = [v * 1000 for v in new_dict.values()]\\n\\ntensor_from_list = tf.convert_to_tensor(weight_vector)\\ntensor_from_list = K.cast(tensor_from_list, \\\"float32\\\")\\n\\nprint(\\\"Weight Vector\\\")\\nprint(weight_vector)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "import tensorflow as tf\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=None)\n",
    "train_data_copy = train_data\n",
    "train_data_copy[\"features\"] = train_data_copy.features.apply(lambda x: str(x))\n",
    "vectors = vectorizer.fit_transform(train_data_copy[\"features\"])\n",
    "\n",
    "idf = vectorizer.idf_\n",
    "\n",
    "# build the weight dictionary\n",
    "new_dict = {}\n",
    "for c in mlb.classes_:\n",
    "    if c in vectorizer.vocabulary_.keys():\n",
    "        new_dict[c] = idf[vectorizer.vocabulary_[c]]\n",
    "    else:\n",
    "        new_dict[c] = np.max(idf)\n",
    "print(\"\\n Printing the TF-IDF for the labels\\n\\n\", new_dict)\n",
    "\n",
    "\n",
    "weight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\n",
    "\n",
    "print(\"\\nPrinting the weight normalised\\n\\n\")\n",
    "print(weight_freq)\n",
    "\n",
    "weight_vector = [v * 1000 for v in new_dict.values()]\n",
    "\n",
    "tensor_from_list = tf.convert_to_tensor(weight_vector)\n",
    "tensor_from_list = K.cast(tensor_from_list, \"float32\")\n",
    "\n",
    "print(\"Weight Vector\")\n",
    "print(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "increased-camera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"def loss_func1(y_true, y_pred):\\n    # tile sprite loss\\n    r_loss=K.mean(K.square(y_true - y_pred), axis=[1,2,3])\\n    loss  =  r_loss\\n    \\n    return loss\\n\\n\\ndef loss_func2(y_true, y_pred):\\n    # text-bce in built\\n    r_loss=binary_crossentropy(y_true, y_pred)\\n    loss  = r_loss\\n    \\n    return loss\\n\\ndef loss_func3(y_true,y_pred):\\n    # multilabel text bce implemented \\n    y_true = K.cast(y_true, 'float32')\\n    y_pred = K.cast(y_pred, 'float32')\\n    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\\n    bce_sum=K.sum(bce_array,axis=1)\\n    loss=bce_sum/19.0\\n    \\n    return loss\\n    \\ndef loss_func4(y_true,y_pred):\\n    # multilabel text weighted bce\\n    y_true = K.cast(y_true, 'float32')\\n    y_pred = K.cast(y_pred, 'float32')\\n    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\\n    weighted_array=bce_array*tensor_from_list\\n    bce_sum=K.sum(weighted_array,axis=1)\\n    loss=bce_sum/19.0\\n    \\n    return loss\\n\\ndef loss_func5(y_true,y_pred):\\n    #\\n    r_loss=binary_crossentropy(y_true, y_pred)\\n    x=y_pred*tensor_from_list\\n    y=K.sum(x,axis=1)\\n    loss=r_loss*y\\n\\n    return loss\\n    \\nlosses ={'image_output_layer':loss_func1,\\n          'text_output_layer':loss_func4,\\n}\\n\\n\\n#tweak loss weights\\nlossWeights={'image_output_layer':0.1,\\n          'text_output_layer':0.9  \\n        }\\n\\n\\ndef check_nonzero(y_true,y_pred):\\n    \\\"\\\"\\\"\\n    Custom metric\\n    Returns sum of all embeddings\\n    \\\"\\\"\\\"\\n    return(K.sum(K.cast(y_pred > 0.4, 'int32')))\\n\\naccuracy={\\n    'image_output_layer':loss_func1,\\n    'text_output_layer': check_nonzero\\n}\";\n",
       "                var nbb_formatted_code = \"def loss_func1(y_true, y_pred):\\n    # tile sprite loss\\n    r_loss = K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])\\n    loss = r_loss\\n\\n    return loss\\n\\n\\ndef loss_func2(y_true, y_pred):\\n    # text-bce in built\\n    r_loss = binary_crossentropy(y_true, y_pred)\\n    loss = r_loss\\n\\n    return loss\\n\\n\\ndef loss_func3(y_true, y_pred):\\n    # multilabel text bce implemented\\n    y_true = K.cast(y_true, \\\"float32\\\")\\n    y_pred = K.cast(y_pred, \\\"float32\\\")\\n    bce_array = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\\n    bce_sum = K.sum(bce_array, axis=1)\\n    loss = bce_sum / 19.0\\n\\n    return loss\\n\\n\\ndef loss_func4(y_true, y_pred):\\n    # multilabel text weighted bce\\n    y_true = K.cast(y_true, \\\"float32\\\")\\n    y_pred = K.cast(y_pred, \\\"float32\\\")\\n    bce_array = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\\n    weighted_array = bce_array * tensor_from_list\\n    bce_sum = K.sum(weighted_array, axis=1)\\n    loss = bce_sum / 19.0\\n\\n    return loss\\n\\n\\ndef loss_func5(y_true, y_pred):\\n    #\\n    r_loss = binary_crossentropy(y_true, y_pred)\\n    x = y_pred * tensor_from_list\\n    y = K.sum(x, axis=1)\\n    loss = r_loss * y\\n\\n    return loss\\n\\n\\nlosses = {\\n    \\\"image_output_layer\\\": loss_func1,\\n    \\\"text_output_layer\\\": loss_func4,\\n}\\n\\n\\n# tweak loss weights\\nlossWeights = {\\\"image_output_layer\\\": 0.1, \\\"text_output_layer\\\": 0.9}\\n\\n\\ndef check_nonzero(y_true, y_pred):\\n    \\\"\\\"\\\"\\n    Custom metric\\n    Returns sum of all embeddings\\n    \\\"\\\"\\\"\\n    return K.sum(K.cast(y_pred > 0.4, \\\"int32\\\"))\\n\\n\\naccuracy = {\\\"image_output_layer\\\": loss_func1, \\\"text_output_layer\\\": check_nonzero}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss_func1(y_true, y_pred):\n",
    "    # tile sprite loss\n",
    "    r_loss=K.mean(K.square(y_true - y_pred), axis=[1,2,3])\n",
    "    loss  =  r_loss\n",
    "    return loss\n",
    "\n",
    "    \n",
    "def loss_func4(y_true,y_pred):\n",
    "    # multilabel text weighted bce\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\n",
    "    weighted_array=bce_array*tensor_from_list\n",
    "    bce_sum=K.sum(weighted_array,axis=1)\n",
    "    loss=bce_sum/13.0\n",
    "    return loss\n",
    "\n",
    "    \n",
    "losses ={'image_output_layer':loss_func1,\n",
    "          'text_output_layer':loss_func4,\n",
    "}\n",
    "\n",
    "\n",
    "#tweak loss weights\n",
    "lossWeights={'image_output_layer':0.1,\n",
    "          'text_output_layer':0.9  \n",
    "        }\n",
    "\n",
    "\n",
    "def check_nonzero(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric\n",
    "    Returns sum of all embeddings\n",
    "    \"\"\"\n",
    "    return(K.sum(K.cast(y_pred > 0.4, 'int32')))\n",
    "\n",
    "accuracy={\n",
    "    'image_output_layer':loss_func1,\n",
    "    'text_output_layer': check_nonzero\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "median-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"from keras import metrics\\n\\nae_sep_output.compile(\\n    optimizer=\\\"adam\\\", loss=losses, loss_weights=lossWeights, metrics=accuracy\\n)\";\n",
       "                var nbb_formatted_code = \"from keras import metrics\\n\\nae_sep_output.compile(\\n    optimizer=\\\"adam\\\", loss=losses, loss_weights=lossWeights, metrics=accuracy\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import metrics\n",
    "\n",
    "ae_sep_output.compile(\n",
    "    optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics=accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rapid-chassis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "732/732 [==============================] - 33s 38ms/step - loss: 1275.0504 - image_output_layer_loss: 7502.0622 - text_output_layer_loss: 583.1602 - image_output_layer_loss_func1: 7502.0622 - text_output_layer_check_nonzero: 53.2916 - val_loss: 337.5922 - val_image_output_layer_loss: 2001.7515 - val_text_output_layer_loss: 152.6855 - val_image_output_layer_loss_func1: 2001.7515 - val_text_output_layer_check_nonzero: 44.0382\n",
      "Epoch 2/10\n",
      "732/732 [==============================] - 25s 34ms/step - loss: 293.0601 - image_output_layer_loss: 1862.4939 - text_output_layer_loss: 118.6787 - image_output_layer_loss_func1: 1862.4939 - text_output_layer_check_nonzero: 44.1218 - val_loss: 212.7433 - val_image_output_layer_loss: 1416.1499 - val_text_output_layer_loss: 79.0316 - val_image_output_layer_loss_func1: 1416.1500 - val_text_output_layer_check_nonzero: 45.5792\n",
      "Epoch 3/10\n",
      "732/732 [==============================] - 26s 35ms/step - loss: 193.4956 - image_output_layer_loss: 1418.5734 - text_output_layer_loss: 57.3759 - image_output_layer_loss_func1: 1418.5733 - text_output_layer_check_nonzero: 45.1357 - val_loss: 127.7747 - val_image_output_layer_loss: 924.7233 - val_text_output_layer_loss: 39.2249 - val_image_output_layer_loss_func1: 924.7233 - val_text_output_layer_check_nonzero: 45.5246\n",
      "Epoch 4/10\n",
      "732/732 [==============================] - 26s 35ms/step - loss: 125.4959 - image_output_layer_loss: 982.9060 - text_output_layer_loss: 30.2280 - image_output_layer_loss_func1: 982.9060 - text_output_layer_check_nonzero: 45.5066 - val_loss: 87.5371 - val_image_output_layer_loss: 686.2650 - val_text_output_layer_loss: 21.0118 - val_image_output_layer_loss_func1: 686.2650 - val_text_output_layer_check_nonzero: 45.4481\n",
      "Epoch 5/10\n",
      "732/732 [==============================] - 27s 36ms/step - loss: 93.5750 - image_output_layer_loss: 787.0467 - text_output_layer_loss: 16.5226 - image_output_layer_loss_func1: 787.0467 - text_output_layer_check_nonzero: 45.5811 - val_loss: 72.4106 - val_image_output_layer_loss: 587.4477 - val_text_output_layer_loss: 15.1842 - val_image_output_layer_loss_func1: 587.4477 - val_text_output_layer_check_nonzero: 45.3497\n",
      "Epoch 6/10\n",
      "732/732 [==============================] - 26s 35ms/step - loss: 74.6962 - image_output_layer_loss: 652.0998 - text_output_layer_loss: 10.5402 - image_output_layer_loss_func1: 652.0998 - text_output_layer_check_nonzero: 45.5536 - val_loss: 52.8147 - val_image_output_layer_loss: 457.3063 - val_text_output_layer_loss: 7.8711 - val_image_output_layer_loss_func1: 457.3063 - val_text_output_layer_check_nonzero: 45.3115\n",
      "Epoch 7/10\n",
      "732/732 [==============================] - 26s 35ms/step - loss: 59.3190 - image_output_layer_loss: 533.0448 - text_output_layer_loss: 6.6828 - image_output_layer_loss_func1: 533.0448 - text_output_layer_check_nonzero: 45.3352 - val_loss: 51.1316 - val_image_output_layer_loss: 447.5738 - val_text_output_layer_loss: 7.0824 - val_image_output_layer_loss_func1: 447.5738 - val_text_output_layer_check_nonzero: 45.3115\n",
      "Epoch 8/10\n",
      "732/732 [==============================] - 26s 36ms/step - loss: 49.6815 - image_output_layer_loss: 460.1316 - text_output_layer_loss: 4.0759 - image_output_layer_loss_func1: 460.1316 - text_output_layer_check_nonzero: 45.3897 - val_loss: 33.9640 - val_image_output_layer_loss: 309.2456 - val_text_output_layer_loss: 3.3772 - val_image_output_layer_loss_func1: 309.2456 - val_text_output_layer_check_nonzero: 45.2459\n",
      "Epoch 9/10\n",
      "732/732 [==============================] - 26s 36ms/step - loss: 39.3343 - image_output_layer_loss: 369.8161 - text_output_layer_loss: 2.6141 - image_output_layer_loss_func1: 369.8161 - text_output_layer_check_nonzero: 45.2960 - val_loss: 30.5660 - val_image_output_layer_loss: 282.8190 - val_text_output_layer_loss: 2.5379 - val_image_output_layer_loss_func1: 282.8190 - val_text_output_layer_check_nonzero: 45.2350\n",
      "Epoch 10/10\n",
      "732/732 [==============================] - 27s 37ms/step - loss: 33.7884 - image_output_layer_loss: 322.0114 - text_output_layer_loss: 1.7636 - image_output_layer_loss_func1: 322.0114 - text_output_layer_check_nonzero: 45.4688 - val_loss: 25.9337 - val_image_output_layer_loss: 240.2036 - val_text_output_layer_loss: 2.1259 - val_image_output_layer_loss_func1: 240.2036 - val_text_output_layer_check_nonzero: 45.2514\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# with loss func 2 that is by using in built cross-entropy loss\\n\\nes = EarlyStopping(\\n    monitor=\\\"val_text_output_layer_loss\\\", mode=\\\"min\\\", verbose=1, patience=2\\n)\\n\\nae_history = ae_sep_output.fit(\\n    [train_image_batch, train_text_batch],\\n    [output_image_batch, output_text_batch],\\n    epochs=10,\\n    batch_size=25,\\n    shuffle=True,\\n    validation_split=0.2,\\n    callbacks=[es],\\n)\";\n",
       "                var nbb_formatted_code = \"# with loss func 2 that is by using in built cross-entropy loss\\n\\nes = EarlyStopping(\\n    monitor=\\\"val_text_output_layer_loss\\\", mode=\\\"min\\\", verbose=1, patience=2\\n)\\n\\nae_history = ae_sep_output.fit(\\n    [train_image_batch, train_text_batch],\\n    [output_image_batch, output_text_batch],\\n    epochs=10,\\n    batch_size=25,\\n    shuffle=True,\\n    validation_split=0.2,\\n    callbacks=[es],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with loss func 2 that is by using in built cross-entropy loss\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_text_output_layer_loss\", mode=\"min\", verbose=1, patience=2\n",
    ")\n",
    "\n",
    "ae_history = ae_sep_output.fit(\n",
    "    [train_image_batch, train_text_batch],\n",
    "    [output_image_batch, output_text_batch],\n",
    "    epochs=10,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprising-representative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "image_dense (Dense)             (None, 4096)         1052672     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "image_reshape (Reshape)         (None, 16, 16, 16)   0           image_dense[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv1 (Conv2DTranspose) (None, 16, 16, 16)   2320        image_reshape[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm1 (BatchNormalizati (None, 16, 16, 16)   64          idecode_conv1[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu1 (ReLU)            (None, 16, 16, 16)   0           idecode_norm1[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "idecode_conv2 (Conv2DTranspose) (None, 16, 16, 32)   4640        idecode_relu1[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense1 (Dense)          (None, 16)           4112        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "idecode_norm2 (BatchNormalizati (None, 16, 16, 32)   128         idecode_conv2[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_reshape (Reshape)          (None, 16)           0           tdecode_dense1[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "idecode_relu2 (ReLU)            (None, 16, 16, 32)   0           idecode_norm2[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tdecode_dense2 (Dense)          (None, 32)           544         text_reshape[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "image_output_layer (Conv2DTrans (None, 16, 16, 3)    867         idecode_relu2[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "text_output_layer (Dense)       (None, 13)           429         tdecode_dense2[1][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,065,776\n",
      "Trainable params: 1,065,680\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"#build the inference model\\n\\ndecoder_input=Input(shape=(256,))\\n\\nd_dense=ae_sep_output.get_layer(\\\"image_dense\\\")(decoder_input)\\nd_reshape=ae_sep_output.get_layer(\\\"image_reshape\\\")(d_dense)\\nd_conv1=ae_sep_output.get_layer(\\\"idecode_conv1\\\")(d_reshape)\\nd_norm1=ae_sep_output.get_layer(\\\"idecode_norm1\\\")(d_conv1)\\nd_relu1=ae_sep_output.get_layer(\\\"idecode_relu1\\\")(d_norm1)\\nd_conv2=ae_sep_output.get_layer(\\\"idecode_conv2\\\")(d_relu1)\\nd_norm2=ae_sep_output.get_layer(\\\"idecode_norm2\\\")(d_conv2)\\nd_relu2=ae_sep_output.get_layer(\\\"idecode_relu2\\\")(d_norm2)\\nd_image_output=ae_sep_output.get_layer(\\\"image_output_layer\\\")(d_relu2)\\n\\nt_dense=ae_sep_output.get_layer(\\\"tdecode_dense1\\\")(decoder_input)\\nt_reshape=ae_sep_output.get_layer(\\\"text_reshape\\\")(t_dense)\\nt_dense2=ae_sep_output.get_layer(\\\"tdecode_dense2\\\")(t_reshape)\\nd_text_output=ae_sep_output.get_layer(\\\"text_output_layer\\\")(t_dense2)\\n\\ndecoder_model=Model(inputs=[decoder_input],outputs=[d_image_output,d_text_output])\\n\\ndecoder_model.summary()\";\n",
       "                var nbb_formatted_code = \"# build the inference model\\n\\ndecoder_input = Input(shape=(256,))\\n\\nd_dense = ae_sep_output.get_layer(\\\"image_dense\\\")(decoder_input)\\nd_reshape = ae_sep_output.get_layer(\\\"image_reshape\\\")(d_dense)\\nd_conv1 = ae_sep_output.get_layer(\\\"idecode_conv1\\\")(d_reshape)\\nd_norm1 = ae_sep_output.get_layer(\\\"idecode_norm1\\\")(d_conv1)\\nd_relu1 = ae_sep_output.get_layer(\\\"idecode_relu1\\\")(d_norm1)\\nd_conv2 = ae_sep_output.get_layer(\\\"idecode_conv2\\\")(d_relu1)\\nd_norm2 = ae_sep_output.get_layer(\\\"idecode_norm2\\\")(d_conv2)\\nd_relu2 = ae_sep_output.get_layer(\\\"idecode_relu2\\\")(d_norm2)\\nd_image_output = ae_sep_output.get_layer(\\\"image_output_layer\\\")(d_relu2)\\n\\nt_dense = ae_sep_output.get_layer(\\\"tdecode_dense1\\\")(decoder_input)\\nt_reshape = ae_sep_output.get_layer(\\\"text_reshape\\\")(t_dense)\\nt_dense2 = ae_sep_output.get_layer(\\\"tdecode_dense2\\\")(t_reshape)\\nd_text_output = ae_sep_output.get_layer(\\\"text_output_layer\\\")(t_dense2)\\n\\ndecoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])\\n\\ndecoder_model.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the inference model\n",
    "\n",
    "decoder_input = Input(shape=(256,))\n",
    "\n",
    "d_dense = ae_sep_output.get_layer(\"image_dense\")(decoder_input)\n",
    "d_reshape = ae_sep_output.get_layer(\"image_reshape\")(d_dense)\n",
    "d_conv1 = ae_sep_output.get_layer(\"idecode_conv1\")(d_reshape)\n",
    "d_norm1 = ae_sep_output.get_layer(\"idecode_norm1\")(d_conv1)\n",
    "d_relu1 = ae_sep_output.get_layer(\"idecode_relu1\")(d_norm1)\n",
    "d_conv2 = ae_sep_output.get_layer(\"idecode_conv2\")(d_relu1)\n",
    "d_norm2 = ae_sep_output.get_layer(\"idecode_norm2\")(d_conv2)\n",
    "d_relu2 = ae_sep_output.get_layer(\"idecode_relu2\")(d_norm2)\n",
    "d_image_output = ae_sep_output.get_layer(\"image_output_layer\")(d_relu2)\n",
    "\n",
    "t_dense = ae_sep_output.get_layer(\"tdecode_dense1\")(decoder_input)\n",
    "t_reshape = ae_sep_output.get_layer(\"text_reshape\")(t_dense)\n",
    "t_dense2 = ae_sep_output.get_layer(\"tdecode_dense2\")(t_reshape)\n",
    "d_text_output = ae_sep_output.get_layer(\"text_output_layer\")(t_dense2)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "french-arrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Entire Model to disk\n",
      "Saved Encoder Model to disk\n",
      "Saved Decoder Model to disk\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"## save model weights, multilabel binarizer\\n\\nimport pickle\\n# saving\\nwith open('model_tokenizer.pickle', 'wb') as handle:\\n    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n    \\n## saving the entire architecture model\\nmodel_json = ae_sep_output.to_json()\\nwith open(\\\"autoencoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nae_sep_output.save_weights(\\\"autoencoder_model.h5\\\")\\nprint(\\\"Saved Entire Model to disk\\\")\\n\\n## saving the encoder part\\nmodel_json = encoding_model.to_json()\\nwith open(\\\"encoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)    \\n# serialize weights to HDF5\\nencoding_model.save_weights(\\\"encoder_model.h5\\\")\\nprint(\\\"Saved Encoder Model to disk\\\")\\n## saving the encoder part\\n\\nmodel_json = decoder_model.to_json()\\nwith open(\\\"decoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)    \\n# serialize weights to HDF5\\ndecoder_model.save_weights(\\\"decoder_model.h5\\\")\\nprint(\\\"Saved Decoder Model to disk\\\")\";\n",
       "                var nbb_formatted_code = \"## save model weights, multilabel binarizer\\n\\nimport pickle\\n\\n# saving\\nwith open(\\\"model_tokenizer.pickle\\\", \\\"wb\\\") as handle:\\n    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n## saving the entire architecture model\\nmodel_json = ae_sep_output.to_json()\\nwith open(\\\"autoencoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nae_sep_output.save_weights(\\\"autoencoder_model.h5\\\")\\nprint(\\\"Saved Entire Model to disk\\\")\\n\\n## saving the encoder part\\nmodel_json = encoding_model.to_json()\\nwith open(\\\"encoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\nencoding_model.save_weights(\\\"encoder_model.h5\\\")\\nprint(\\\"Saved Encoder Model to disk\\\")\\n## saving the encoder part\\n\\nmodel_json = decoder_model.to_json()\\nwith open(\\\"decoder_model.json\\\", \\\"w\\\") as json_file:\\n    json_file.write(model_json)\\n# serialize weights to HDF5\\ndecoder_model.save_weights(\\\"decoder_model.h5\\\")\\nprint(\\\"Saved Decoder Model to disk\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## save model weights, multilabel binarizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open(\"model_tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(mlb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "## saving the entire architecture model\n",
    "model_json = ae_sep_output.to_json()\n",
    "with open(\"autoencoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "ae_sep_output.save_weights(\"autoencoder_model.h5\")\n",
    "print(\"Saved Entire Model to disk\")\n",
    "\n",
    "## saving the encoder part\n",
    "model_json = encoding_model.to_json()\n",
    "with open(\"encoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "encoding_model.save_weights(\"encoder_model.h5\")\n",
    "print(\"Saved Encoder Model to disk\")\n",
    "## saving the encoder part\n",
    "\n",
    "model_json = decoder_model.to_json()\n",
    "with open(\"decoder_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "decoder_model.save_weights(\"decoder_model.h5\")\n",
    "print(\"Saved Decoder Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "reflected-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y is Ready. Shape :  (2540, 13)\n",
      "True Y is Ready. Shape : (2540, 13)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"predicted_image, predicted_text = ae_sep_output.predict(\\n    [test_image_batch, test_text_batch]\\n)\\ny_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\\ny_pred = np.array(y_pred)\\nprint(\\\"Predicted Y is Ready. Shape : \\\", y_pred.shape)\\n\\ny_true = test_text_batch\\ny_true = np.array(y_true)\\nprint(\\\"True Y is Ready. Shape :\\\", y_true.shape)\";\n",
       "                var nbb_formatted_code = \"predicted_image, predicted_text = ae_sep_output.predict(\\n    [test_image_batch, test_text_batch]\\n)\\ny_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\\ny_pred = np.array(y_pred)\\nprint(\\\"Predicted Y is Ready. Shape : \\\", y_pred.shape)\\n\\ny_true = test_text_batch\\ny_true = np.array(y_true)\\nprint(\\\"True Y is Ready. Shape :\\\", y_true.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "modern-midwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Array shape  (2540, 16, 16, 3)\n",
      "True Array shape  (2540, 16, 16, 3)\n",
      "Mean MSE 249.02893\n",
      "Median MSE 35.89482\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"true_image=[]\\nfor i in range(len(test_image_batch)):\\n    current_image = test_image_batch[i]\\n    current_image_centre=test_image_batch[i][16:16+16,16:16+16,:]\\n    true_image.append(current_image_centre)\\ntrue_image=np.array(true_image)\\nprint(\\\"Predicted Array shape \\\",predicted_image.shape)\\nprint(\\\"True Array shape \\\", true_image.shape)\\n\\nmse_dist=[]\\nfor idx in range(len(true_image)):\\n    y_true_image=true_image[idx]\\n    y_true_image=y_true_image.reshape(16,16,3)\\n    \\n    y_pred_image=predicted_image[idx]\\n    y_pred_image=y_pred_image.reshape(16,16,3)\\n    \\n    mse_dist.append(np.mean(np.subtract(y_true_image,y_pred_image)**2))\\n    \\nprint(\\\"Mean MSE\\\",np.mean(mse_dist))\\nprint(\\\"Median MSE\\\",np.median(mse_dist))\";\n",
       "                var nbb_formatted_code = \"true_image = []\\nfor i in range(len(test_image_batch)):\\n    current_image = test_image_batch[i]\\n    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\\n    true_image.append(current_image_centre)\\ntrue_image = np.array(true_image)\\nprint(\\\"Predicted Array shape \\\", predicted_image.shape)\\nprint(\\\"True Array shape \\\", true_image.shape)\\n\\nmse_dist = []\\nfor idx in range(len(true_image)):\\n    y_true_image = true_image[idx]\\n    y_true_image = y_true_image.reshape(16, 16, 3)\\n\\n    y_pred_image = predicted_image[idx]\\n    y_pred_image = y_pred_image.reshape(16, 16, 3)\\n\\n    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\\n\\nprint(\\\"Mean MSE\\\", np.mean(mse_dist))\\nprint(\\\"Median MSE\\\", np.median(mse_dist))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "municipal-johns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def valid_divide(num,den):\\n    count=0\\n    result={}\\n    for idx in range(len(num)):\\n        if num[idx]==den[idx]==0:\\n            continue\\n        elif num[idx]!=0 and den[idx]!=0:\\n            result[idx]=num[idx]/den[idx]\\n            count+=1\\n        elif num[idx]!=0 and den[idx]==0 or num[idx]==0 and den[idx]!=0:\\n            count+=1\\n            result[idx]=0.0\\n    return result,count\";\n",
       "                var nbb_formatted_code = \"def valid_divide(num, den):\\n    count = 0\\n    result = {}\\n    for idx in range(len(num)):\\n        if num[idx] == den[idx] == 0:\\n            continue\\n        elif num[idx] != 0 and den[idx] != 0:\\n            result[idx] = num[idx] / den[idx]\\n            count += 1\\n        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\\n            count += 1\\n            result[idx] = 0.0\\n    return result, count\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def valid_divide(num, den):\n",
    "    count = 0\n",
    "    result = {}\n",
    "    for idx in range(len(num)):\n",
    "        if num[idx] == den[idx] == 0:\n",
    "            continue\n",
    "        elif num[idx] != 0 and den[idx] != 0:\n",
    "            result[idx] = num[idx] / den[idx]\n",
    "            count += 1\n",
    "        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\n",
    "            count += 1\n",
    "            result[idx] = 0.0\n",
    "    return result, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "particular-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro Label Based Precision 0.999739654499619\n",
      "Macro Label Based Recall 0.993341686330762\n",
      "Macro Label Based Accuracy 0.9930819063263079\n",
      "\n",
      "Micro Label Based Precision 0.9991300565463245\n",
      "Micro Label Based Recall 0.9978279756733276\n",
      "Micro Label Based Accuracy 0.9969618055555556\n",
      "\n",
      "Example Based Precision 0.9988188976377953\n",
      "Example Based Recall 0.9983595800524934\n",
      "Example Based Accuracy 0.9980971128608923\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"print(\\\"\\\\nMacro Label Based Precision\\\", precision_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Recall\\\", recall_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Accuracy\\\", accuracy_macro(y_true, y_pred))\\n\\nprint(\\\"\\\\nMicro Label Based Precision\\\", precision_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Recall\\\", recall_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Accuracy\\\", accuracy_micro(y_true, y_pred))\\n\\nprint(\\\"\\\\nExample Based Precision\\\", example_based_precision(y_true, y_pred))\\nprint(\\\"Example Based Recall\\\", example_based_recall(y_true, y_pred))\\nprint(\\\"Example Based Accuracy\\\", example_based_accuracy(y_true, y_pred))\";\n",
       "                var nbb_formatted_code = \"print(\\\"\\\\nMacro Label Based Precision\\\", precision_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Recall\\\", recall_macro(y_true, y_pred))\\nprint(\\\"Macro Label Based Accuracy\\\", accuracy_macro(y_true, y_pred))\\n\\nprint(\\\"\\\\nMicro Label Based Precision\\\", precision_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Recall\\\", recall_micro(y_true, y_pred))\\nprint(\\\"Micro Label Based Accuracy\\\", accuracy_micro(y_true, y_pred))\\n\\nprint(\\\"\\\\nExample Based Precision\\\", example_based_precision(y_true, y_pred))\\nprint(\\\"Example Based Recall\\\", example_based_recall(y_true, y_pred))\\nprint(\\\"Example Based Accuracy\\\", example_based_accuracy(y_true, y_pred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_representation",
   "language": "python",
   "name": "tile_representation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
