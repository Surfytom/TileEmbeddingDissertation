{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "# split into train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from notebook_utils import initialize_environment\n",
    "\n",
    "initialize_environment()\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from utils.data_loading.load_data import get_tile_data\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-butterfly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##loading train and testing data\n",
    "\n",
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "data = get_tile_data(data_directory, json_directory)\n",
    "print(\"\\nThe size of total data is\", data.shape)\n",
    "data = shuffle(data)\n",
    "train_data, test_data = train_test_split(data, test_size=0.10, random_state=42)\n",
    "\n",
    "print(\"\\nThe size of the train data is \", train_data.shape)\n",
    "print(\"The size of the test data is \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the multilabel binarizer\n",
    "with open(\"../model/model_tokenizer.pickle\", \"rb\") as handle:\n",
    "    mlb = pickle.load(handle)\n",
    "print(\"Feature Dictionary Loaded\")\n",
    "total_features = len(mlb.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "display(\"Features\", mlb.classes_)\n",
    "\n",
    "# load entire autoencoder architecture\n",
    "json_file = open(\"../model/autoencoder_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "ae_sep_output = model_from_json(loaded_model_json)\n",
    "ae_sep_output.load_weights(\"../model/autoencoder_model.h5\")\n",
    "print(\"Loaded Entire Autoencoder Model from the Disk\")\n",
    "\n",
    "# load the encoding architecture and weights\n",
    "json_file = open(\"../model/encoder_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_model = model_from_json(loaded_model_json)\n",
    "encoding_model.load_weights(\"../model/encoder_model.h5\")\n",
    "print(\"Loaded Encoder Model from the Disk\")\n",
    "\n",
    "# load the decoding architecture and weights\n",
    "json_file = open(\"../model/decoder_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "decoding_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "decoding_model.load_weights(\"../model/decoder_model.h5\")\n",
    "print(\"Loaded Decoder Model from the Disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Input Output Training Batches\n",
    "print(\"Building Training Batches\")\n",
    "\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "train_image_batch = []\n",
    "for train_path in train_data[\"image_path\"]:\n",
    "    tile = image.load_img(train_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    train_image_batch.append(tile_sprite)\n",
    "train_image_batch = np.array(train_image_batch)\n",
    "train_text_batch = []\n",
    "for i in range(len(train_data[\"features\"])):\n",
    "    text_ = mlb.transform(train_data[\"features\"][i : i + 1])\n",
    "    train_text_batch.append(text_)\n",
    "train_text_batch = np.array(train_text_batch).reshape(\n",
    "    train_data.shape[0], total_features\n",
    ")\n",
    "\n",
    "output_image_batch = []\n",
    "for i in range(len(train_image_batch)):\n",
    "    current_image = train_image_batch[i]\n",
    "    current_image_centre = train_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    output_image_batch.append(current_image_centre)\n",
    "output_image_batch = np.array(output_image_batch)\n",
    "output_text_batch = []\n",
    "for i in range(len(train_text_batch)):\n",
    "    current_text = train_text_batch[i]\n",
    "    output_text_batch.append(current_text)\n",
    "output_text_batch = np.array(output_text_batch)\n",
    "print(\"Training Data Ready\")\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "\n",
    "# Build Input Output Test Batches\n",
    "print(\"Building Testing Batches\")\n",
    "\"\"\"Note : Add Generators\"\"\"\n",
    "test_image_batch = []\n",
    "for test_path in test_data[\"image_path\"]:\n",
    "    tile = image.load_img(test_path, target_size=(48, 48))\n",
    "    tile_sprite = image.img_to_array(tile)\n",
    "    test_image_batch.append(tile_sprite)\n",
    "test_image_batch = np.array(test_image_batch)\n",
    "test_text_batch = []\n",
    "for i in range(len(test_data[\"features\"])):\n",
    "    text_ = mlb.transform(test_data[\"features\"][i : i + 1])\n",
    "    test_text_batch.append(text_)\n",
    "test_text_batch = np.array(test_text_batch).reshape(test_data.shape[0], total_features)\n",
    "print(\"\\n\\nTesting Data Ready\")\n",
    "print(\"Train Image batch shape\", test_image_batch.shape)\n",
    "print(\"Train Text batch shape\", test_text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-eclipse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))\n",
    "\n",
    "\n",
    "def valid_divide(num, den):\n",
    "    count = 0\n",
    "    result = {}\n",
    "    for idx in range(len(num)):\n",
    "        if num[idx] == den[idx] == 0:\n",
    "            continue\n",
    "        elif num[idx] != 0 and den[idx] != 0:\n",
    "            result[idx] = num[idx] / den[idx]\n",
    "            count += 1\n",
    "        elif num[idx] != 0 and den[idx] == 0 or num[idx] == 0 and den[idx] != 0:\n",
    "            count += 1\n",
    "            result[idx] = 0.0\n",
    "    return result, count\n",
    "\n",
    "\n",
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-encoding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_representation",
   "language": "python",
   "name": "tile_representation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
