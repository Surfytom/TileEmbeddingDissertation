{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bizarre-macro",
   "metadata": {},
   "source": [
    "# Tile Embedding: A General Representation for Level Generation.\n",
    "### Authors: Mrunal Jadhav and Matthew Guzdial \n",
    "\n",
    "<!-- Paper: \n",
    "If you use the data please cite : -->\n",
    "\n",
    "## Install Dependencies\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Extracting the Data\n",
    "\n",
    "For this implementation, we use the data from [VGLC Corpus](https://github.com/TheVGLC/TheVGLC). Our training data includes five games: *Super Mario Bros, Kid Icarus, Legend of Zelda, Lode Runner, Megaman*. We train a X-shaped autoencoder which takes two inputs:\n",
    "\n",
    "1. Tile Sprite with its neighbourhood context.\n",
    "2. Affordances associated with the tile sprite. \n",
    "\n",
    "The data extraction takes places as follows: \n",
    "> We slide a 48 * 48 window over the level images to extract the tile sprites with its local context. As preprocessing, we have performed prelimnary image manipulations to fit the dimensions of the levels images. For instance some SMB levels had extra pixels along the vertical/horizontal axis which results in off-centered tile extraction.Lode Runner levels has 8 * 8 tile size which we upscaled to 16 * 16 using the PIL library. The preprocessed dataset is stored in [vglc](\"../data/vglc/\") directory\n",
    "\n",
    "<img src=\"../images/sliding_window.png\">\n",
    "\n",
    "To extract the context for one game run the following \n",
    "\n",
    "1. Move to directory: context_extraction\n",
    "```\n",
    "cd notebooks/context_extraction\n",
    "```\n",
    "\n",
    "2. Run the following command in shell\n",
    "```\n",
    "python extract_context.py\n",
    "```\n",
    "\n",
    "On navigating to the folder *data > context_data >* each game folder should be populated by its visual context sorted by the centre tile.\n",
    "The json files generated in each game directory is a dictionary with key as the centre tile and value enlisting all possible neighbourhoods it. \n",
    "\n",
    "## Training autoencoder\n",
    "\n",
    "1. The jupyter notebook \"notebooks > autoencoder_training.ipynb\" provides a step by step guide for autoencoder training. \n",
    "\n",
    "2. You can also run the following commands to train the autoencoder and save the weights:\n",
    "\n",
    ">a. Move to the directory: notebooks\n",
    "```\n",
    "cd notebooks/\n",
    "```\n",
    ">b. Run the following command in shell\n",
    "```\n",
    "python autoencoder_training.py\n",
    "```\n",
    "\n",
    "3. Load the directly provided architecture and weights. Sample Notebook: \n",
    "\n",
    "## Generating Level Representation using trained autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-rally",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tile_representation",
   "language": "python",
   "name": "tile_representation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
