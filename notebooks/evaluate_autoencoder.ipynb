{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd53ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from collections import Counter\n",
    "\n",
    "from notebook_utils import initialize_environment\n",
    "initialize_environment()\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "from ast import literal_eval\n",
    "from utils.evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from utils.data_loading.load_data import get_tile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac9a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "\n",
    "game_data_path=\"../data/game_data.csv\"\n",
    "train_data_path=\"../data/train_data.csv\"\n",
    "test_data_path=\"../data/test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bed1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickle_file(path):\n",
    "    with open(path,\"rb\") as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98f5194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dictionary Loaded\n",
      "The feature dictionary has size 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['block', 'breakable', 'climbable', 'collectable', 'element',\n",
       "       'empty', 'hazard', 'moving', 'openable', 'passable', 'pipe',\n",
       "       'solid', 'wall'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Training Testing Batches loaded\n",
      "Train Image batch shape (18494, 48, 48, 3)\n",
      "Train Text batch shape (18494, 13)\n",
      "Train Output Image batch shape (18494, 16, 16, 3)\n",
      "Train Output Text batch shape (18494, 13)\n",
      "Test Image batch shape (2055, 48, 48, 3)\n",
      "Test Text batch shape (2055, 13)\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "data=pd.read_csv(game_data_path)\n",
    "train_data=pd.read_csv(train_data_path)\n",
    "test_data=pd.read_csv(test_data_path)\n",
    "\n",
    "data['features'] = data.features.apply(lambda x: literal_eval(str(x)))\n",
    "train_data['features'] = train_data.features.apply(lambda x: literal_eval(str(x)))\n",
    "test_data['features'] = test_data.features.apply(lambda x: literal_eval(str(x)))\n",
    "\n",
    "# loading multi-label binarizer\n",
    "mlb=get_pickle_file(\"../model/model_tokenizer.pickle\")\n",
    "print(\"Feature Dictionary Loaded\")\n",
    "total_features = len(mlb.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "display(\"Features\", mlb.classes_)\n",
    "\n",
    "# loading the batches\n",
    "# training \n",
    "train_image_batch=get_pickle_file(\"../data/train_image_batch.pickle\")\n",
    "train_text_batch=get_pickle_file(\"../data/train_text_batch.pickle\")\n",
    "output_image_batch=get_pickle_file(\"../data/output_image_batch.pickle\")\n",
    "output_text_batch=get_pickle_file(\"../data/output_text_batch.pickle\")\n",
    "\n",
    "#testing\n",
    "test_image_batch=get_pickle_file(\"../data/test_image_batch.pickle\")\n",
    "test_text_batch=get_pickle_file(\"../data/test_text_batch.pickle\")\n",
    "\n",
    "print(\"\\Training Testing Batches loaded\")\n",
    "\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Train Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Train Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "print(\"Test Image batch shape\", test_image_batch.shape)\n",
    "print(\"Test Text batch shape\", test_text_batch.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94c906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 07:35:24.544131: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-09 07:35:24.544260: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Entire Autoencoder Model from the Disk\n",
      "Loaded Encoder Model from the Disk\n",
      "Loaded Decoder Model from the Disk\n"
     ]
    }
   ],
   "source": [
    "# loading the saved models\n",
    "\n",
    "json_file = open(\"../model/autoencoder_model_test.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "ae_sep_output = model_from_json(loaded_model_json)\n",
    "ae_sep_output.load_weights(\"../model/autoencoder_model_test.h5\")\n",
    "print(\"Loaded Entire Autoencoder Model from the Disk\")\n",
    "\n",
    "# load the encoding architecture and weights\n",
    "json_file = open(\"../model/encoder_model_test.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_model = model_from_json(loaded_model_json)\n",
    "encoding_model.load_weights(\"../model/encoder_model_test.h5\")\n",
    "print(\"Loaded Encoder Model from the Disk\")\n",
    "\n",
    "# load the decoding architecture and weights\n",
    "json_file = open(\"../model/decoder_model_test.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "decoding_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "decoding_model.load_weights(\"../model/decoder_model_test.h5\")\n",
    "print(\"Loaded Decoder Model from the Disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b409f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 07:35:25.412911: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-09 07:35:25.413611: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-09-09 07:35:29.897942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y is Ready. Shape :  (2055, 13)\n",
      "True Y is Ready. Shape : (2055, 13)\n",
      "Predicted Array shape  (2055, 16, 16, 3)\n",
      "True Array shape  (2055, 16, 16, 3)\n",
      "Mean MSE 334.68558\n",
      "Median MSE 82.10172\n"
     ]
    }
   ],
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)\n",
    "\n",
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bba438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro Label Based Precision 0.9931025132611384\n",
      "Macro Label Based Recall 0.9994441464632311\n",
      "Macro Label Based Accuracy 0.9925466597243695\n",
      "\n",
      "Micro Label Based Precision 0.9986866298923036\n",
      "Micro Label Based Recall 0.9981622473090049\n",
      "Micro Label Based Accuracy 0.9968536969061353\n",
      "\n",
      "Example Based Precision 0.9988645579886455\n",
      "Example Based Recall 0.9987834549878345\n",
      "Example Based Accuracy 0.9984184914841849\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fa04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
